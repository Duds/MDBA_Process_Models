MDBA Basin Plan Review 2026: Submissions Process Service Concept & Blueprint

Phase 3 Design Deliverable — Service Concept and Blueprint

13 May 2025  
Version 0.3 \[REFACTOR SECTION ARRANGEMENT\] DRAFT

| Contact |
| :---- |
| Level 2, 10 Bond Street,Sydney, NSW, 2000 \+61 2 9657 0999 [info@atturra.com](mailto:info@atturra.com) |
| Noel Derwort Executive General Manager T	\+61 2 9657 0999M	\+61 431 114 940E	noel.derwort@atturra.com Will Goodwin Manager T	\+61 2 9657 0999M	\+61 466 713 317E	will.goodwin@atturra.com Dale Rogers Service Designer T	\+61 2 9657 0999M	\+61 400 944 492E	dale.rogers@atturra.com |

Contents

[**How to Use This Document	7**](#how-to-use-this-document)

[**1**	**Introduction	8**](#introduction)

[1.1	Context	8](#context)

[1.2	Objectives for the Service	9](#objectives-for-the-service)

[1.3	The Purpose of a Service Concept	10](#the-purpose-of-a-service-concept)

[1.4	Personas, Archetypes, Scenarios, Journeys, & Blueprints	10](#personas,-archetypes,-scenarios,-journeys,-&-blueprints)

[Personas	10](#personas)

[Archetypes	10](#archetypes)

[Scenarios	11](#scenarios)

[Customer Journeys	11](#customer-journeys)

[Service Blueprints	11](#service-blueprints)

[1.5	Submission Journeys	12](#submission-journeys)

[1.6	Strategic Alignment with MDBA Digital Strategy	13](#strategic-alignment-with-mdba-digital-strategy)

[**2**	**Service Design	14**](#service-design)

[2.1	Design Principles	14](#design-principles)

[2.2	Design Elements	16](#design-elements)

[**3**	**Service Concept	20**](#service-concept)

[3.1	Scenarios	20](#scenarios-1)

[3.2	Service Products overview	21](#service-products-overview)

[3.3	Key Themes and Identified opportunities	23](#key-themes-and-identified-opportunities)

[3.4	Engaged Contribution	26](#engaged-contribution)

[3.4.1	Overview	26](#overview)

[3.4.2	Engaged Contribution Journey (Part 1: Pre-Submission Experience)	30](#engaged-contribution-journey-\(part-1:-pre-submission-experience\))

[3.4.3	Engaged Contribution Journey (Part 2: Post-Submission Experience)	31](#engaged-contribution-journey-\(part-2:-post-submission-experience\))

[3.9.2	Service Blueprint – Engaged Contribution	32](#heading=h.74mv0ue8m75t)

[Archetype: Engaged Contributor	32](#heading=h.176l3gvfaa4w)

[Positioning Statement:	32](#heading=h.b98ka0ixudu1)

[Journey Description	32](#heading=h.mdork8v3du7a)

[3.5	Process Coordination	33](#process-coordination)

[3.5.1	Overview	33](#overview-1)

[3.5.2	Process Coordination Journey (Part 1: Intake and Progression)	36](#process-coordination-journey-\(part-1:-intake-and-progression\))

[3.5.3	Process Coordination Journey (Part 2: Closure and Support)	37](#process-coordination-journey-\(part-2:-closure-and-support\))

[3.6	37](#heading)

[3.11.2 Service Blueprint – Process Coordination	38](#heading=h.560dj9x640sn)

[Archetype: Process Steward	38](#heading=h.kmlgzgfrurcj)

[Description:	38](#heading=h.vfwpxnnb6zho)

[Positioning Statement:	38](#heading=h.e3xaf3b8atw)

[Journey Description	38](#heading=h.h17hh3lhurvd)

[3.7	Platform oversight	39](#platform-oversight)

[3.7.1	Overview	39](#overview-2)

[3.7.2	Platform oversight Journey (Part 1: Setup, Access & Monitoring)	42](#platform-oversight-journey-\(part-1:-setup,-access-&-monitoring\))

[3.7.3	Platform oversight Journey (Part 2: Security, Incidents & Evaluation)	43](#platform-oversight-journey-\(part-2:-security,-incidents-&-evaluation\))

[3.8	43](#heading-1)

[3.12.2 Service Blueprint – Platform Oversight	44](#heading=h.v6u2mbvknx90)

[Archetype: Platform Guardian	44](#heading=h.tw6reegscj5b)

[Description:	44](#heading=h.yxpc2d8oe2wi)

[Positioning Statement:	44](#heading=h.t2biaijo0nwi)

[Journey Description	44](#heading=h.8frf7je6f4nl)

[3.9	Compliance Assurance	45](#compliance-assurance)

[3.9.1	Overview	45](#overview-3)

[3.9.2	Compliance Assurance Journey (Part 1: Pre-Lodgement & Review)	48](#compliance-assurance-journey-\(part-1:-pre-lodgement-&-review\))

[3.10	49](#heading-2)

[3.10.1	Compliance Assurance Journey (Part 2: Publication & Legal Finalisation)	49](#compliance-assurance-journey-\(part-2:-publication-&-legal-finalisation\))

[3.12.2 Service Blueprint – Compliance Custodian	50](#heading=h.22ca2l4t4851)

[Archetype: Compliance Custodian	50](#heading=h.b6du045up1z9)

[Description:	50](#heading=h.m8733k4bzuuo)

[Positioning Statement:	50](#heading=h.nd29u4dejy8q)

[Journey Description	50](#heading=h.5l11tx40n9ge)

[3.11	Insight Generation	51](#insight-generation)

[3.11.1	Overview	51](#overview-4)

[3.11.2	Strategic Synthesiser Journey (Part 1: Data Intake & Insights Generation)	54](#strategic-synthesiser-journey-\(part-1:-data-intake-&-insights-generation\))

[3.11.3	Strategic Synthesiser Journey (Part 2: Executive Support & Evaluation)	55](#strategic-synthesiser-journey-\(part-2:-executive-support-&-evaluation\))

[3.12.2 Service Blueprint – Strategic Synthesis	56](#heading=h.xcf225gw0rfk)

[Archetype: Strategic Synthesiser	56](#heading=h.kr04mqo0f7re)

[Description:	56](#heading=h.x1yvlq80yzxd)

[Positioning Statement:	56](#heading=h.yq3qhe8jrtdj)

[Journey Description	56](#heading=h.vhjk0s1t9l6e)

[**4**	**Operating Model	57**](#operating-model)

[4.1	Governance Structure	57](#governance-structure)

[4.2	Delivery Roles	57](#delivery-roles)

[4.3	Ongoing Operations	58](#ongoing-operations)

[4.4	Review and Improvement	58](#review-and-improvement)

[4.5	Operating Model Overview	59](#operating-model-overview)

[Description of Diagram	60](#description-of-diagram)

[4.6	Decision and Escalation Responsibilities	61](#decision-and-escalation-responsibilities)

[4.7	Transition to BAU and Service Ownership	61](#transition-to-bau-and-service-ownership)

[4.8	Operating Assumptions	62](#operating-assumptions)

[4.9	Performance and Success Measures	62](#performance-and-success-measures)

[4.10	Service Lifecycle and Legacy Management	63](#service-lifecycle-and-legacy-management)

[**5**	**Capability Map	64**](#capability-map)

[**6**	**Functional Requirements Summary	70**](#functional-requirements-summary)

[**7**	**Non-Functional Requirements Summary	74**](#non-functional-requirements-summary)

[**8**	**Artefact & Template Recommendations	76**](#artefact-&-template-recommendations)

[**Appendix A Persona-Archetype Mapping	78**](#appendix-a-persona-archetype-mapping)

[**Appendix B Alignment to Water Act 2007 s51 obligations	80**](#appendix-b-alignment-to-water-act-2007-s51-obligations)

[**Appendix C Compliance Checkpoints and Controls	82**](#appendix-c-compliance-checkpoints-and-controls)

[**Appendix D Data & Privacy Flow Map	84**](#appendix-d-data-&-privacy-flow-map)

[D.1 Overview Flow Description	84](#d.1-overview-flow-description)

[D.2 Privacy Safeguards by Stage	85](#d.2-privacy-safeguards-by-stage)

[D.3 Flow Map	86](#d.3-flow-map)

[**Appendix E: Objectives Mapping	87**](#appendix-e:-objectives-mapping)

[**Appendix F Service Products	89**](#appendix-f-service-products)

[Submission Guidance & Consent	89](#submission-guidance-&-consent)

[Submission Intake & Interface	90](#submission-intake-&-interface)

[Processing, Triage & Workflow	91](#processing,-triage-&-workflow)

[Reporting & Feedback	92](#reporting-&-feedback)

[Records, Archive & Governance	92](#records,-archive-&-governance)

[Co-design & Engagement Tools	93](#co-design-&-engagement-tools)

[Ethics, Risk & ICIP Governance	94](#ethics,-risk-&-icip-governance)

[Implementation & Handover Tools	94](#implementation-&-handover-tools)

[**Appendix G Submission Channels Table	96**](#appendix-g-submission-channels-table)

[**Appendix H Submission Data Object Model	98**](#appendix-h-submission-data-object-model)

[**Appendix I Workflow Register	101**](#appendix-i-workflow-register)

[**Appendix J Service Concept Background	106**](#appendix-j-service-concept-background)

[The purpose of the service concept	106](#the-purpose-of-the-service-concept)

[**Appendix K Previous Work and Resources	107**](#appendix-l-previous-work-and-resources)

[**Appendix L Strategic Crosswalk	109**](#appendix-k-strategic-crosswalk)

[MDBA Digital Strategy Pillars	109](#mdba-digital-strategy-pillars)

[Table K.1 – Design Principles vs MDBA Digital Strategy	109](#table-k.1-–-design-principles-vs-mdba-digital-strategy)

[Table K.2 – Key Service Features vs MDBA Digital Strategy Pillars	110](#table-k.2-–-key-service-features-vs-mdba-digital-strategy-pillars)

[Table K.2 – Expanded Objectives Alignment	112](#table-k.2-–-expanded-objectives-alignment)

[**Appendix M Interviews Conducted	113**](#appendix-l-previous-work-and-resources)

[8.1.1	Interviews were conducted with the following key stakeholders and users	113](#interviews-were-conducted-with-the-following-key-stakeholders-and-users)

[**Appendix N Glossary	115**](#appendix-n-submission-process-+-damf-alignment-swimlane)

# **How to Use This Document** {#how-to-use-this-document}

This progress document provides a structured and partial view of the MDBA Basin Plan Review Submissions Service Concept. It is intended to support internal review, stakeholder engagement, and alignment during the design and implementation planning phases.

It includes:

* A summary of the service context and design objectives

* The high-level structure linking Personas → Archetypes → Journeys → Blueprints

* Focused journeys and blueprints

* Core design principles and elements that underpin the full-service concept

**This version is not a complete service specification**. Instead, it highlights the foundational thinking and priority components relevant at this stage of the project. Full journey coverage, system requirements, capability maps, and supporting appendices will be provided in the final submission.

1. **Introduction**

   1. **Context**

The Murray–Darling Basin Authority (MDBA) is legislatively required under Section 51 of the Water Act 2007 to undertake a comprehensive review of the Basin Plan every ten years. In preparation for the 2026 review, the MDBA has initiated the redesign of its public submissions process to ensure it is fit-for-purpose, scalable, inclusive, and compliant with legislative, privacy, and cultural obligations. This service concept builds on the insights captured during the Discovery Phase (April 2025), where internal deep dives, legislative reviews, and user persona mapping were undertaken to frame the needs, risks, and functional expectations of the process.

Key contextual drivers include:

* **Legislative obligations** under the Water Act 2007 to invite and consider submissions from both Basin States and the public for a minimum of 12 weeks.

* **Diverse stakeholders** including community members, First Nations representatives, state governments, campaign groups, and MDBA internal teams.

* **Submission format complexity**, including text, image, audio, video, and oral formats — requiring flexible intake and analysis systems.

* **Privacy, FoI, and ICIP compliance** requirements for handling, redacting, and publishing sensitive or cultural information.

* **Volume expectations** of 5,000–10,000+ submissions, with potential for high-volume campaign participation.

* **System requirements** for secure, onshore storage (Azure), WCAG AA compliance, and robust consent tracking and redaction workflows.

* **Feedback and transparency expectations**, including *“What We’ve Heard”* reporting and visible submission status tracking.

* **Alignment to enterprise frameworks** such as DAMF and MDBA’s Enterprise Architecture principles (e.g., Configure-before-Code, reuse-first approach).

This concept sets the foundation for service delivery planning, governance alignment, and user-centred co-design in the implementation phase.

2. **Objectives for the Service**

The future submissions process described in this service concept is a critical enabler of the MDBA’s statutory obligations under the Water Act 2007 and broader commitments to inclusive, transparent, and ethical consultation. The process must accommodate a wide range of submitters and submission types, while also ensuring compliance, security, and operational efficiency.

This service concept supports the MDBA in delivering a future service model that is:

* Inclusive and accessible to all stakeholder groups — including First Nations, regional communities, advocacy bodies, and government stakeholders.

* operationally scalable and capable of handling high volumes of submissions, including diverse formats and campaign-style inputs.

* Legally defensible and compliant with key legislation, including privacy, ICIP, FoI, and records management requirements.

* Transparent and accountable, with visible pathways from submission to consideration, and mechanisms for timely feedback and reporting.

* Adaptable and sustainable, allowing for future reuse, iteration, and cross-program application within MDBA.

The objectives below reflect the strategic focus areas for the future submissions process:

**Table 1: Strategic Focus Areas**

|  | Design a seamless, guided intake experience that supports multiple channels and formats. |
| :---- | :---- |
|  | Embed privacy, consent, and ICIP protections throughout the lifecycle of each submission. |
|  | Enable workflow automation, redaction, triage and routing to support internal processing efficiency. |
|  | Support real-time reporting, analytics, and campaign monitoring to inform public communication and executive insight. |
|  | Provide transparent status tracking, public reporting, and publishable outputs that meet accessibility and compliance standards. |
|  | Align with MDBA enterprise architecture, data governance, and digital service standards. |

3. **The Purpose of a Service Concept**

The service concept defines the future vision for how MDBA will deliver and operate the Basin Plan Review submissions process. It sets out the intended experience for users, the system capabilities required to support that experience, and the design principles that will guide implementation.

Rather than prescribing detailed solutions, this concept provides a structured foundation to align stakeholders, support co-design, and inform downstream artefacts such as journey maps, service blueprints, and system requirements.

It ensures the future process is user-centred, legally compliant, and operationally sustainable — while supporting transparency, trust, and reuse across the broader BPR program.

More information on the Service Concept is at [**Appendix I**](#bookmark=id.oz5d38jmbfzn).

4. **Personas, Archetypes, Scenarios, Journeys, & Blueprints**

This service concept uses a layered design model, progressing from user research through to implementation tools. The structure ensures traceability of user needs and alignment with system and process design. The pathway is:

### **Personas** {#personas}

Initial user personas were developed during discovery to capture granular motivations, behaviours, and concerns. These included First Nations storytellers, community advocates, industry reps, and public sector coordinators, among others.

### **Archetypes** {#archetypes}

Personas were synthesised into five representative archetypes to anchor the design of systemic journeys:

| Archetype | Represents... |
| :---- | :---- |
| **Engaged Contributor** | Individuals and groups lodging submissions |
| **Process Steward** | Internal triage and workflow managers |
| **Platform Guardian** | IT and data custodians |
| **Compliance Custodian** | Legal and privacy reviewers |
| **Strategic Synthesiser** | Analysts and policy advisors using submission data |

### **Scenarios** {#scenarios}

Scenarios illustrate key situations and user interactions across the submission lifecycle, enabling designers to test edge cases, identify system requirements, and validate user needs in context. Scenarios developed for this process included:

* Community Citizen lodging a public submission

* First Nations Representative navigating ICIP consent protocols

* Government official submitting jurisdictional feedback in structured form

* Campaign group lodging large volumes of coordinated submissions

* Internal MDBA staff triaging, analysing, and processing submissions

These scenarios draw on user research and internal deep dives, including specific requirements for diversity of media types, campaign submission handling, consent workflows, and privacy and security compliance

### **Customer Journeys** {#customer-journeys}

Each archetype is mapped to an end-to-end customer journey showing key phases, activities, system touchpoints, and emotional states. These journeys are the backbone of service design.

### **Service Blueprints** {#service-blueprints}

Journeys are then translated into detailed blueprints. Each blueprint provides:

* Touchpoints and technology

* Staff roles and backstage actions

* Supporting processes, policies, and artefacts

* Risks and system requirements

This structured approach enables MDBA to design inclusively while ensuring legal defensibility, scalability, and stakeholder transparency.

5. **Submission Journeys**

The submissions process must support a diverse set of users — from community members and First Nations contributors to internal analysts and system custodians. These users interact with the process in different ways, depending on their goals, responsibilities, and context. To design an inclusive and scalable experience, five distinct submission journeys have been defined. These journeys represent the primary modes of interaction with the submissions process.

Each journey is linked to a representative user archetype — a simplified model of behaviour, motivation, and need — which helps guide design, policy, and technology decisions throughout the process.

**Table 2: Submission Journeys Outline**

| Journey | Description | Related Archetype |
| :---- | :---- | :---- |
| **Engaged Contribution** | Individuals and groups preparing and submitting content to be considered in the Review. | Engaged Contributor |
| **Process Coordination** | Staff triaging, managing, and progressing submissions through internal review stages. | Process Steward |
| **Platform oversight** | IT and data custodians ensuring systems are secure, accessible, and operational. | Platform Guardian |
| **Compliance Assurance** | Legal and governance staff managing consent, privacy, ICIP, and FoI obligations. | Compliance Custodian |
| **Insight Generation** | Analysts and decision-makers extracting meaning from submissions to shape Review outcomes. | Strategic Synthesiser |

These journeys are not mutually exclusive — a user may move between them over time — but they provide a structured way to analyse, design, and support interactions throughout the submissions process. Archetypes will be developed in more detail in later sections to inform system design, engagement strategy, and internal workflows.

6. **Strategic Alignment with MDBA Digital Strategy**

This service concept has been designed to align closely with the MDBA Digital Strategy 2023–25, ensuring that the solution not only meets the functional needs of stakeholders but is also consistent with the authority’s broader digital, governance, and operational objectives.

MDBA’s digital strategy outlines four pillars of transformation:

* **Digital Workplace and Service Accessibility**

* **Information Management and Governance**

* **ICT Operations and Resilience**

* **Data Ethics, Privacy and Risk**

The submissions service directly contributes to these goals through:

* **Automation and digitisation of high-volume processes**, replacing email and manual handling

* **User-centred interface design** to support inclusivity and trust

* **Metadata-rich records and compliance integration**, aligning with DAMF and FOI protocols

* **Consent, ICIP and publication controls**, supporting CARE principles and transparent consideration.

Design principles such as Compliance by Design, User-Centred Inclusion, and Data Stewardship and Sovereignty are embedded across journey phases and service interactions. These are reinforced by technology features like secure cloud hosting, automated redaction workflows, and real-time intake monitoring — all aligned with MDBA’s ambition to modernise and consolidate digital service delivery.

For a full mapping of design and system features to MDBA strategic priorities, see [**Appendix J.**](#bookmark=id.dpuf99aptdza)

2. **Service Design**

   1. **Design Principles**

The following principles underpin the design of the Basin Plan Review submissions process. They ensure the service is inclusive, compliant, efficient, and respectful of all stakeholders — particularly First Nations peoples and public contributors. These principles reflect legislative obligations, system design best practice, and user-centred values surfaced during the Discovery Phase. They guide how the submissions process should be built, managed, and experienced across all phases and journeys.

**Table 5: Insert Table of Design Principles**

| Design Principle | Description |
| :---: | ----- |
| 🔐Compliance by Design | Embed Water Act, Privacy, FoI, ICIP, and accessibility obligations from the outset — not as a postscript. |
| 🧍‍♀️User-Centred Inclusion | Design services that are intuitive, accessible, and respectful of diverse users, including those with cultural, regional, or technological barriers. |
| ⚙️Configure Before Code | Prioritise proven, configurable platforms and processes over bespoke development to maximise maintainability and alignment with MDBA EA principles. |
| 📈Scalable and Flexible | Support a wide range of submission formats and volumes — from individual citizens to mass campaigns — without degrading performance or experience. |
| 🛡️Data Stewardship and Sovereignty | Ensure secure, onshore data handling with respect for Indigenous knowledge protocols, aligned to DAMF and ICIP safeguards. |
| 👁️Transparent Consideration and Feedback | Provide submitters with confidence that their input is received, understood, and contributes to Review outcomes. |
| 🧭Ethical and Respectful Engagement | Honour cultural protocols, support Free, Prior and Informed Consent (FPIC), and treat all contributions with integrity and care. |

2. **Design Elements**

While the design principles define the values underpinning the submissions process, the design elements translate those principles into tangible service features, behaviours, and system characteristics. These elements ensure that the intent of the process — inclusivity, defensibility, clarity, and ease of use — is reflected in every interaction, from front-end user interfaces to back-end workflows and governance structures.

Each design element is specific enough to guide development and decision-making, yet broad enough to allow for flexibility across different platforms, delivery models, and engagement scenarios. They function as a toolkit to shape service behaviours, helping delivery teams and policy leads consistently align to the process vision. These elements will also inform future system configurations, implementation roadmaps, and service testing activities.

**Table 6: Table of Design Elements**

| Design Elements |  | Description |
| :---: | ----- | ----- |
| 🔐Compliance by Design | DE01 | Legal and ethical requirements (Water Act, Privacy, FoI, ICIP) are built into workflows, templates, and system logic. |
|  | DE02 | Audit trails capture every interaction with a submission, including redaction, review, and publication actions. |
| 🧍‍♀️User-Centred Inclusion | DE03 | All submission interfaces are WCAG AA compliant, simple to navigate, and support a range of formats, devices, and literacy levels. |
|  | DE04 | Users can self-serve support via contextual help, plain language guides, and status tracking. |
|  | DE05 | Users can save progress and return to their submission, allowing for drafting, review, and collaborative preparation. |
|  | DE06 | The portal supports translation or localisation into common regional languages to enable inclusive participation. |
| ⚙️Configure Before Code | DE07 | The process uses off-the-shelf tools configured to MDBA requirements, avoiding unnecessary custom development. |
|  | DE08 | System rules (e.g. triage, tagging, escalation) are driven by editable configuration, not hardcoded logic. |
|  | DE09 | Submission types and topic categories are editable by admin users via a no-code interface, avoiding code changes for updates. |
|  | DE10 | System logic (e.g. triage routing, notification rules) is visible to admins and auditable without developer intervention. |
| 📈Scalable and Flexible | DE11 | Submissions of all types — written, oral, visual — are supported across self-service and assisted channels. |
|  | DE12 | Submission processing (e.g. auto-tagging, metadata capture, routing) is scalable and can handle high volumes. |
|  | DE13 | Campaign submissions can be grouped, de-duplicated, and analysed without biasing the overall weighting of insights. |
|  | DE14 | Submissions can be linked or grouped by contributor, campaign, or organisation for traceability without conflating influence. |
| 🛡️Data Stewardship and Sovereignty | DE15 | All submission data is stored securely onshore in compliance with DAMF and ICIP expectations. |
|  | DE16 | ICIP and consent metadata are embedded at point of collection and preserved through the data lifecycle. |
|  | DE17 | Redaction tools are embedded within workflows, enabling in-system removal of sensitive information before publishing. |
| Design Elements |  | Description |
| 👁️Transparent Consideration and Feedback | DE18 | Submitters receive confirmation, visibility of process status, and clear reporting on how submissions contributed to outcomes. |
|  | DE19 | A public-facing explanation of “consideration” is published, along with examples of how submissions informed outcomes. |
|  | DE20 | Contributors can opt-in to receive targeted updates or summaries aligned to their submission theme or archetype. |
| 🧭Ethical and Respectful Engagement | DE21 | Consent options are time-bound, revocable, and aligned with CARE and FPIC principles. |
|  | DE22 | Culturally sensitive content is flagged, secured, and excluded from inappropriate publication or reuse. |

3. **Service Concept**

This section sets out the core journeys (and associated service blueprints) that define how different archetypes will interact with the Basin Plan Review submissions process. These journeys are informed by legislative obligations, operational insights, and user research conducted during the discovery phase.

Each journey represents a distinct pathway through the submissions process, aligned to a specific user archetype and their interaction with the system. Together, they capture the diversity of user needs — from members of the public making a submission, to internal staff processing and analysing that submission, to those responsible for platform integrity, legal compliance, and strategic reporting.

The journeys include:

* **Engaged Contribution** — the experience of community members and stakeholders preparing and submitting their views

* **Process Coordination** — the workflow followed by MDBA staff managing intake, triage, and submission handling

* **Platform oversight** — the responsibilities of ICT and data custodians in ensuring a secure, accessible, and scalable system

* **Compliance Assurance** — the legal and privacy checks that underpin responsible submission handling and publication

* **Insight Generation** — the activities of analysts and executives drawing meaning from submissions to shape review outcomes.

These journeys form the basis for subsequent system design, user interface development, and internal capability alignment. They are not technical blueprints, but structured representations of the end-to-end experience from multiple perspectives.

1. **Scenarios**

To illustrate the breadth and complexity of user interactions with the submissions process, a series of representative scenarios were developed during the Design Phase. These are not exhaustive but highlight typical experiences aligned to each of the five submission journeys and their associated archetypes.

Each scenario reflects the needs, constraints, and expectations of users engaging with different parts of the process — from external community members making individual submissions to internal staff managing triage, compliance, and analysis workflows.

**Note:** External users were not available for direct engagement during this phase. Personas and archetypes have been developed based on desktop research and insights provided by MDBA staff to reflect representative user needs and behaviours.

**Table 4: Journey to Artefact Mapping**

| Journey | Scenario | Archetype |
| :---- | :---- | :---- |
| **Engaged Contribution** | A community member wishes to submit a personal story and video about local water conditions. | **Engaged Contributor** |
| **Process Coordination** | An MDBA team member receives 3,000 campaign submissions and needs to triage them efficiently. | **Process Steward** |
| **Platform oversight** | An IT administrator configures role-based access and redaction workflows for flagged content. | **Platform Guardian** |
| **Compliance Assurance** | A legal officer assesses whether a submission with ICIP content meets consent requirements. | **Compliance Custodian** |
| **Insight Generation** | A data analyst prepares a thematic dashboard summarising sentiment trends by topic cluster. | **Strategic Synthesiser** |

2. **Service Products overview**

The delivery of the Basin Plan Review (BPR) submissions process relies on a suite of service products—both digital and non-digital—that together make the service function as designed. These products are not standalone systems or artefacts, but essential components that support and enable user interactions, back-end processing, compliance, and feedback.

In the context of the BPR Submissions Process, service products include templates, consent forms, tracking mechanisms, communications materials, triage rulesets, and technical tools that directly support the end-to-end journey from Invitation to Feedback. They underpin how the process is delivered, measured, and experienced by both internal actors and external contributors.

Each product plays a specific role across the submission lifecycle stages and aligns to the design principles and service functions established earlier in this document. The full register of identified and recommended service products is included in [**Appendix F**](#bookmark=id.o7q8vsjmlpyy)

**Note:** As the process design matures, this list may evolve to accommodate final implementation needs and updated legislative or policy requirements.

3. **Key Themes and Identified opportunities**

| Submission Journey | Phase Description | Key opportunities | Key Pains |
| :---: | ----- | ----- | ----- |
| **EngagedContributor** | **Awareness & Access** — Notices invitation via media, events, or third-party channels; accesses submission portal. | Use multiple awareness channels Targeted messaging for hard-to-reach groups Early publication of submission guide | Missed invitations Unclear entry points Lack of trust in official sources |
|  | **Understanding Scope** — Reviews discussion paper and what is in/out of scope. | Clear in-scope/out-of-scope statements Guided summaries and FAQs | Confusion about what counts as a valid submission Risk of disengagement |
|  | **Submission Preparation** — Prepares submission in written, audio, or visual format. | Multi-format support Downloadable templates Community language versions | Literacy, language, or tech barriers Format incompatibility |
|  | **Lodgement & Consent** — Submits via portal or mail; provides consent or flags ICIP. | Consent options built into lodgement Auto-acknowledgement receipt ICIP tagging | Unclear consent implications Fear of misuse of cultural or sensitive data |
|  | **Feedback Expectations** — Seeks transparency and visibility over how submissions are used. |  reporting Trackable lodgement status | No confirmation of influence Feelings of tokenism |
| **ProcessSteward** | **Pre-launch Setup** — Uploads discussion paper, sets metadata, tests portal. | Preloaded templates and tags Testing periods with staff walkthroughs | Ambiguity in tagging logic Comms delays during rollout |
|  | **Triage & Intake** — Processes campaign and individual submissions, flags ICIP. | Campaign deduplication Auto-tagging logic Dashboard triage queues | Manual workload spikes Mislabelling risks Burnout under volume pressure |
|  | **Review & Routing** — Assigns to reviewers, redactors, or legal. | Role-based access Automated notifications and handovers | Bottlenecks if routing rules unclear Multiple systems causing drop-offs |
|  | **Archiving & Reporting** — Ensures metadata and recordkeeping. | Integration with records management systems Final snapshot archiving tools | Version control gaps Audit log inconsistencies |
|  | **Support & Troubleshooting** — Helps users, manages portal issues. | Live support chat FAQ and error message improvements | Repetitive queries from users Insufficient escalation pathways |

| Submission Journey | Phase Description | Key opportunities | Key Pains |
| :---: | ----- | ----- | ----- |
| **PlatformGuardian** | Security & Configuration — Enforces SSO, MFA, secure storage. | Align with MDBA EA and DAMF Azure-hosted secure tenancy | Role confusion between ICT and business teams Risk of misconfiguration |
|  | **Availability & Monitoring** — Tracks uptime, access logs, and performance. | Real-time monitoring dashboards SLA definitions | Low visibility of issues until they impact users |
|  | **Data Integrity & Sovereignty** — Ensures metadata capture, ICIP handling, audit trails. | ICIP flags and secure zones Cultural metadata tagging | No historical approach to ICIP classification High risk of mishandling sensitive content |
|  | **Incident Response** — Handles access breaches, outages, or unexpected load. | Playbooks for security and privacy incidents | Fragmented incident ownership Post-incident reviews not embedded |
|  | **Post-Process Review** — Evaluates system performance and architecture fit. | System usage analytics Cost-benefit assessment tools | Lack of telemetry and usage analytics |
| **ComplianceCustodian** | **Pre-launch Review** — Reviews consent, ICIP, and redaction frameworks. | Tiered consent model (broad/narrow/ICIP) Legal sign-off checklist | Interpretation differences across teams Limited legal resources at pace |
|  | **Submission Monitoring** — Scans for sensitive or high-risk content. | Redaction queue Legal flagging rulesets | Late-stage privacy issues Inconsistent application of defamation and ICIP handling |
|  | **Consideration Review** — Evaluates if consideration criteria are met. | Clear rules on what constitutes “consideration” Decision traceability tools | Ambiguity around partial or campaign submissions |
|  | **FoI/Publication Planning** — Applies redactions and eligibility rules. | Consent-aligned publication logic Split views (public/internal) | No shared publication criteria Risk of over or under-exposure |
|  | **Risk & Audit Reporting** — Maintains logs and reports for audit and governance. | Integrated privacy dashboard Legal defensibility scorecard | Gaps in data lineage or provenance |

| Submission Journey | Phase Description | Key opportunities | Key Pains |
| :---: | ----- | ----- | ----- |
| **StrategicSynthesiser** | Data Preparation — Receives tagged, cleaned dataset. | Pre-configured dashboards and templates Structured themes aligned to discussion paper | Inconsistent metadata Late triage hinders insights timeline |
|  | **Insights Generation** — Conducts thematic and sentiment analysis. | Power BI with campaign insights Use of keywords and taxonomies | Risk of bias from poorly grouped themes |
|  | **What We’ve Heard** — Prepares accessible, transparent reports. | Configurable narrative outputs Charts, quotes, sentiment tagging | ICIP content may be excluded from summary Lack of formatting support for mixed media |
|  | **Briefings & Reports** — Crafts outputs for executives and stakeholders. | Rapid export into PPT/DOC Highlights linked to raw submission themes | Difficulty evidencing how input shapes decisions |
|  | **Process Evaluation** — Reflects on what was captured and missed. | Post-review feedback dashboard Lessons learned repository | No clear metrics for evaluation |

4. **Engaged Contribution**

   1. **Overview**

The Engaged Contribution service type represents the experience of individuals, communities, and organisations who wish to participate in the Basin Plan Review by lodging a submission. This includes concerned citizens, advocacy groups, First Nations representatives, community alliances, and stakeholder organisations such as environmental groups and industry associations.

This service type focuses on enabling meaningful, accessible, and respectful participation in the submission process. It encompasses the stages of awareness, understanding scope, preparing and lodging a submission, and receiving feedback on how contributions were considered.

**Note:** Scope Clarification

This service type covers:

○	Individual and group submissions from members of the public, First Nations communities, and non-governmental stakeholders.  
○	Both self-service and assisted pathways (e.g. Riverside Chats).  
○	All engagement leading up to and including submission lodgement and post-submission feedback to contributors.

This service type does not cover:

○	Internal triage or SME review of submissions (*covered in [**Process Coordination**](#bookmark=id.u8u9holqw271)*).  
○	Technical systems setup, data ingestion, or storage workflows  
(*covered in [**Platform Oversight**](#bookmark=id.tt80l95em7eq)*).  
○	Legal escalation or redaction decisions (*covered in [**Compliance Assurance**](#bookmark=id.1qthm6v616sh)*).  
○	Reporting synthesis and insight generation (*covered in [**Strategic Synthesiser**](#bookmark=id.1qthm6v616sh)*).

**Table 7: Engaged Contribution – Service Overview Table**

| Question | Description |
| :---- | :---- |
| **What is the purpose of the service type?** | The Engaged Contribution service enables individuals, organisations, and institutions across the Basin to submit information, views, knowledge, or evidence into the Basin Plan Review process. It provides multiple pathways for contributors — including community members, First Nations groups, NGOs, industry bodies, state agencies, and commercial entities — to lodge submissions in a manner that is accessible, respectful, and legally compliant. It supports democratic participation, ensures procedural fairness under Section 51 of the Water Act 2007, and upholds principles of inclusion, transparency, and equity. |
| **Who will benefit and why?** | This service benefits a broad ecosystem of contributors: **Concerned citizens and community members** benefit from a low-barrier pathway to express lived experience and values. **First Nations groups** benefit from culturally appropriate pathways that allow oral, visual, and place-based knowledge to be shared respectfully. **Industry Peak Body Representatives use** the process to provide detailed technical reports on behalf of member organisations, seeking recognition of economic or regulatory concerns. **Water Market Participants** (e.g. irrigators, brokers, traders) contribute expertise on water policy, pricing, and allocation impacts. **State Government Submission Coordinators** may make formal contributions on behalf of their jurisdictions, often with supporting evidence and structured commentary.  Each group contributes different types of content but all benefit from knowing their views are being considered in a structured and traceable way. |
| **Who will access the service type? (User Personas)** | The primary user personas for this service include: **Engaged Contributor** – Individuals or informal groups submitting community views or concerns. **Cultural Contributor** – First Nations submitters who provide place-based or oral content. **Campaign organiser** – NGOs, advocacy alliances, and large-scale mobilisation groups. **Industry Peak Body Representative** – Structured representatives of agriculture, irrigation, or environment-focused sectors offering detailed policy positions. **Water Market Participant** – Traders, brokers, or irrigators commenting on water markets or Basin economics. **State Government Submission Coordinator** – Public servants tasked with formal submissions on behalf of a jurisdiction. |
| **What are the primary channels for the service?** | To maximise inclusion and meet a wide range of contributor preferences, the following channels are offered: **online submission portal** – Structured form allowing for attachments, ICIP tagging, and guided consent. **Facilitated engagement** – Staff-supported channels like Riverside Chats where oral or informal inputs are transcribed. **Email and file upload** – For technical submissions from states, industry, or water professionals. **Mail or physical drop-off** – For contributors in regions with limited digital access. **Partnered access points** – Such as council offices or libraries offering assisted digital submission kiosks. |
| **What technology is expected to be required to support the service?** | Supporting this service type requires an integrated set of technologies and features: **A WCAG AA-compliant portal** with support for attachments, multiple formats, and accessibility tools. **Save-and-return functionality** to support contributors who need to pause and continue later. **A consent capture engine** that allows granular, revocable, and ICIP-specific consent to be logged at time of submission. **Tagging and triage integration** to pre-process content based on format, theme, or sensitivity. **A status notification system** to confirm receipt and flag key process milestones to contributors. **Secure cloud storage with audit trail** to retain sensitive content and enable future defensibility. |

.

2. **Engaged Contribution Journey (Part 1: Pre-Submission Experience)**

| Engaged Contribution | Awareness & Access |  |  | Understanding Scope |  |  |  | Submission Preparation |  |  |  |
| :---- | ----- | ----- | ----- | ----- | ----- | ----- | ----- | ----- | ----- | ----- | ----- |
| **Key Activities**The core tasks, actions, and decisions users perform at each stage of the journey. | 📣 | 🌐 | 📰 | 📘 | ❓ | 🔍 | 🧭 | ✍️ | 🗣️ | 🎨 | 📎 |
|  | Learns about the Review via public campaigns, MDBA newsletter, or local government channels. | Accesses the submissions portal through the MDBA website or a shared link. | Reads supporting content such as emails or community flyers explaining the process. | opens and reads the Discussion Paper, seeking to understand themes and questions. | Scans for key issues of interest. | Tries to determine if their concern is relevant. | Looks for real examples or past submissions to model theirs on. | Begins preparing their thoughts in writing, or recording media on a phone or device. | Gathers community or group input to incorporate. | Selects media to upload (images, PDFs, recordings). | Completes any consent or submission declaration forms. |
| **Service Improvements**Enhancements to systems, processes, or tools that support a better experience or reduce risk. | 📢 | 🧾 | 📽️ | 📄 | 🧮 | 📚 | 🔍 | 🧰 | 📱 | 🗂️ | ✅ |
|  | Broad distribution strategy using digital and community channels including translated content and accessible formats. | Click-through from campaign comms directly to portal home. | Summary explainer videos, visual FAQs and step-by-step process diagrams. | A plain English discussion paper and summary version to support comprehension across literacy levels. | In-scope/out-of-scope filters and examples. | Smart prompts based on common user questions. | *“What to include”* tips and real-world submission samples. | Multi-format templates including written, audio, video and community co-submission pathways. | oral/video upload functionality that is mobile-responsive. | Drag-and-drop upload interface with live preview. | Guided consent and privacy prompts embedded in form. |
| **User Experience**How the user feels or reflects on the process — their perceptions, needs, and satisfaction at each stage. | 💡 | 👣 | 👁️ | 🧠 | 🧩 | 🤝 | 🙋‍♀️ | 🗣️ | 🫂 | 🎭 | 📝 |
|  | *“I received the invite in a community newsletter — it looked important and easy to follow up.”* | *“I clicked the link and was straight into the portal without confusion.”* | *“I feel confident this is something I can participate in — I see people like me have submitted before.”* | *“I’m starting to see how my views connect to the bigger picture — and what they want from me.”* | *“It’s helpful to know what’s in-scope so I don’t waste time.”* | *“I wasn’t sure at first, but the guide helped me feel prepared.”* | *“Seeing a real example gave me the confidence to start.”* | *“I was able to speak my story into my phone and upload it — I wouldn’t have written it down otherwise.”* | *“We had a community conversation and recorded it — the system made it easy to submit.”* | *“I liked being able to attach my artwork and map with my comments.”* | *“The consent part made me feel my input would be treated respectfully.”* |

3. **Engaged Contribution Journey (Part 2: Post-Submission Experience)**

| Engaged Contribution | Lodgement & Confirmation |  |  | Waiting & Visibility |  |  |  | Feedback & Influence |  |  |  |
| :---- | ----- | ----- | ----- | ----- | ----- | ----- | ----- | ----- | ----- | ----- | ----- |
| **Key Activities**The core tasks, actions, and decisions users perform at each stage of the journey. | 📤 | 📩 | 🛡️ | ⏳ | 📝 | 🔔 | 🔄 | 📘 | 📢 | 📬 | 🧾 |
|  | Submits their entry via portal or assisted channel. | Receives confirmation and summary of submission. | Confirms consent settings and visibility preferences. | Waits for response during the consultation window. | Reads reminder about next steps and indicative process timeframes. | Receives alerts on major milestones. | Hopes to be notified about the impact of their input. | Reads the *“What We’ve Heard”* report when published. | Looks for attribution of their themes. | Notices summary content via newsletters. | Downloads outcome documents. |
| **Service Improvements**Enhancements to systems, processes, or tools that support a better experience or reduce risk. | 📤 | 📨 | 🔐 | ⏱️ | 📋 | 🔔 | 📈 | 📑 | 📣 | 🗞️ | 💾 |
|  | Submission receipt screen and email confirmation with timestamp. | Auto-generated summary sent with opt-in to regular community newsletter. | Consent interface includes visibility options. | Estimated timeline shown on portal dashboard. | Static information page "*Submissions will be considered between \[date range\]; you will not receive further updates until reports are published.*" | Notification engine for user-specific milestones. | Analytics dashboard summarises common themes. | *“What We’ve Heard”* formatted for accessibility and distribution. | Contributors’ topics visible in output themes. | Email campaigns summarise insights. | Archive and downloadable final materials. |
| **User Experience**How the user feels or reflects on the process — their perceptions, needs, and satisfaction at each stage. | 🙌 | 📬 | ✅ | 🧘‍♂️ | 🧐 | 📳 | 🤞 | 🤓 | 😌 | 💌 | 🗂️ |
|  | *“It was satisfying to get an instant confirmation that my submission was received.”* | *“The summary email helped me remember what I said.”* | *“I appreciated being able to choose how mine would be shown.”* | *“Now I wait… but at least I know when I might hear back.”* | *"I knew I wouldn’t get detailed updates, but it was good to understand what happens next."* | *“Getting that update made me feel included.”* | *“I’m hopeful that what I said made a difference.”* | *“I could actually see my issues reflected in the report — that really matters to me.”* | *“It’s reassuring to see common concerns captured.”* | *“The newsletter update gave me closure.”* | *“I saved the report for future reference.”* |

| Awareness & Motivation | Preparation | Lodgement | Acknowledgement | Feedback |
| ----- | ----- | ----- | ----- | ----- |
| **Evidence** |  |  |  |  |
| Facebook post, flyer, community event | Discussion paper, plain English submission guide, in-scope checklist | Submission form, ICIP and privacy prompt, file upload interface | Confirmation email, dashboard confirmation message | “What We’ve Heard” online report, newsletter update |
| **Journey** |  |  |  |  |
| Hears about the Review and considers participating | Reads background material and starts writing | Completes the form and uploads submission | Receives confirmation and feels reassured | Sees their theme mentioned in report and feels acknowledged |
| **Touchpoints** |  |  |  |  |
| 📱 Facebook🧾 Community flyer🧑‍🤝‍🧑 Word-of-mouth | 📘 Discussion guide💡 Scope explainer🖋️ Draft workspace | 💻 Submission portal📎 Upload field✅ Consent selector | ✉️ Email confirmation👓 Dashboard status bar | 🌐 Report webpage📬 Email digest |
| **Employee Actions** |  |  |  |  |
| Comms team posts social media content and delivers physical materials | Helpdesk fields user questions and maintains portal content | Backend processes metadata tagging and stores the submission securely | System issues confirmation; helpdesk available for follow-up | Comms team curates quotes and themes for public reporting |
| **Technology** |  |  |  |  |
| Website CMS, campaign email tools, QR codes | Web portal with save-and-return function, metadata tagging engine | Consent capture module, ICIP tagging interface, upload validation | Email notification engine, submission dashboard tracker | Publishing CMS, Power BI dashboard for volume/themes |
| **Backstage Actions** |  |  |  |  |
| Comms materials reviewed and approved by stakeholder teams | Portal content and guides reviewed by Legal and ICIP advisors | Submission flows into triage queue with routing metadata | Submission is indexed and stored with retention tags | Submission themes cross-checked with archive; quotes linked for reporting |
| **Supporting Processes** |  |  |  |  |
| Consultation communications plan, social content calendar | Submission content policy, metadata taxonomy schema | Consent and ICIP flagging protocols, triage escalation matrix | Records and Privacy policy enforcement, audit log creation | Public reporting process, Legal/ICIP review of publication candidates |
| **Regulations/Policies** |  |  |  |  |
| Water Act 2007 (s51), MDBA Communications Standards | Privacy Act 1988, MDBA Submission Content Policy | ICIP Protocols, FOI Act 1982, Care Principles | Records Management Policy, MDBA Retention Schedule | Public Disclosure Guidelines, FOI Exemption Framework |
| **Design Features** |  |  |  |  |
| Multi-channel promotion (e.g. social, print) WCAG AA-compliant portal Supports five channels | Save-and-return functionality In-scope filtering Metadata preview | Granular consent capture Mobile-optimised upload ICIP-aware tagging | Auto-confirmation with timestamp Status page with progress markers | Quote tagging engine Submission-insight linkage Campaign load balancing |

5. **Process Coordination**

   1. **Overview**

The Process Coordination service type represents the core operational activities undertaken by MDBA and partner staff to manage submissions from intake through to archival. This includes triage, tagging, escalation, routing for review, and ensuring traceable, compliant handling of all inputs received during the submission window.

The focus of this service is on internal coordination — ensuring that each submission is accurately recorded, appropriately assessed, and efficiently passed through the stages of internal consideration, redaction (if needed), and reporting. While it is largely invisible to the public, the quality and reliability of this service type are critical to the defensibility and success of the Basin Plan Review.

**Note:** Scope Clarification

This service type covers:

○	Internal workflows for receiving, validating, tagging, and routing submissions.  
○	Tracking the volume and status of submissions.  
○	Escalating submissions for legal, cultural, or technical review.  
○	Managing archiving, metadata retention, and preparation for reporting.

This service type does not cover:

○	Public-facing interfaces or communication with contributors  
(*covered in [**Engaged Contribution**](#bookmark=id.tp3r9l5pgfwv)*).  
○	Legal determination of publication readiness  
(*covered in [**Compliance Assurance**](#bookmark=id.1qthm6v616sh)*).  
○	The analysis, synthesis, or thematic reporting of submission content  
(*covered in [**Strategic Synthesiser**](#bookmark=id.cip8me6iz8o8)*).  
○	Underlying ICT platforms and system operations  
(*covered in [**Platform oversight**](#bookmark=id.tt80l95em7eq)*).

**Table 8: Process Coordination – Service Overview Table**

| Question | Description |
| :---- | :---- |
| **What is the purpose of the service type?** | The Process Coordination service exists to ensure that the flow of submissions through the system is accurate, accountable, and efficient. It enables staff to triage incoming content, assign it for review, manage escalation to legal or cultural advisors, and track processing across internal teams. This supports compliance with procedural fairness, information governance, and internal efficiency goals while building the foundations for insight generation and reporting. |
| **Who will benefit and why?** | This service benefits internal staff including Submission Managers, SME reviewers, Legal and Privacy officers, and ICT platform custodians. Efficient coordination ensures staff are not overwhelmed during peak periods, submissions are handled consistently, and ICIP or legal risks are flagged early. It also benefits contributors indirectly by ensuring their submissions are not lost, delayed, or mishandled — preserving public trust and institutional integrity. |
| **Who will access the service type? (User Personas)** | The key internal personas using this service include: **Process Steward** – Manages submission flow, triage logic, and assignment to SMEs. **Compliance Custodian** – Monitors flagged submissions and reviews redaction decisions. **Platform Guardian** – Supports metadata integrity, routing logic, and archival workflows. **Legal and ICIP Reviewers** – Access submissions escalated for sensitive or restricted content decisions. |
| **What are the primary channels for the service?** | Process Coordination will occur primarily through: **Internal processing dashboards** showing live submission counts, flagged items, and workflow statuses. **Workflow engines and queues** integrated with metadata and tagging rules. **Escalation pathways** embedded in systems to alert legal, cultural, or leadership reviewers. **Manual intake and triage tools** for non-digital or offline submissions (e.g. Riverside Chats paper notes). |
| **What technology is expected to be required to support the service?** | This service type relies on multiple backend systems working together: **A submission management dashboard** showing volume, status, and priority tiers. **Configurable triage and tagging logic**, including auto-categorisation and risk-based escalation triggers. **Role-based access control** with audit trail tracking. **Redaction and review workflow tools** integrated with SME and legal processes. **Submission archival system** with retention logic and metadata mapping. |

2. **Process Coordination Journey (Part 1: Intake and Progression)**

| Process Coordination | Pre-launch Setup |  |  | Triage & Intake |  |  |  | Routing & Review |  |  |  |
| :---- | ----- | ----- | ----- | ----- | ----- | ----- | ----- | ----- | ----- | ----- | ----- |
| **Key Activities**The core tasks, actions, and decisions users perform at each stage of the journey. | 🛠️ | 🗂️ | 🧪 | 📥 | 🧾 | 🧩 | 🚩 | 🔄 | 📤 | 🔍 | 📌 |
|  | Configures portal with discussion paper, tagging schema, submission format options. | Loads key documents and guidelines into the system. | Tests portal with internal staff for usability. | Receives submissions in various formats via portal, email, or mail. | Applies intake checklist and records metadata. | Tags campaign vs. individual submissions. | Flags submissions with legal or ICIP risks. | Assigns submissions to SMEs or redaction queues based on topic or risk. | Escalates unclear submissions for review. | Monitors throughput and triage efficiency. | Updates triage matrix based on emerging needs. |
| **Service Improvements**Enhancements to systems, processes, or tools that support a better experience or reduce risk. | 🧰 | 📘 | 🧪 | 📨 | 🧮 | 🏷️ | ⚠️ | 📍 | 🗃️ | 📊 | 📋 |
|  | Pre-configured templates and field mappings for metadata capture. | System preview and internal testing phase. | Feedback loop for portal setup validation. | Dashboard shows incoming submission volumes in real time. | Auto-tagging rules and confidence thresholds. | Suggested topics with training data models. | Built-in redaction or privacy flag prompts. | Integrated triage-to-review workflow with assignments. | Escalation triggers tied to content types. | Real-time dashboards for triage metrics. | Editable triage criteria list in admin view. |
| **User Experience**How the user feels or reflects on the process — their perceptions, needs, and satisfaction at each stage. | 📦 | 🧑‍💼 | 🧪 | 🤹 | 🧾 | 🧠 | 😬 | 🚦 | 🧭 | 📈 | 🧾 |
|  | *“The setup was smooth — we had all the assets pre-loaded and tested.”* | *“It was helpful to preview the workflow before launch.”* | *“Quick testing revealed some logic gaps we could fix.”* | *“There’s a steady stream of submissions — glad we can see the load daily.”* | *“The checklist makes sure we don’t miss steps.”* | *“Smart tagging saved hours already.”* | *“I know when to flag — the prompts are helpful.”* | *“Routing logic helped us scale — we’re not bottlenecked.”* | *“I know when to escalate and where it goes.”* | *“The dashboard shows where we’re falling behind.”* | *“We’re tweaking triage rules based on what we’re seeing.”* |

3. **Process Coordination Journey (Part 2: Closure and Support)**

| Process Coordination | Archiving & Records |  |  | Support & Troubleshooting |  |  |  | Reporting & Closeout |  |  |  |
| :---- | ----- | ----- | ----- | ----- | ----- | ----- | ----- | ----- | ----- | ----- | ----- |
| **Key Activities**The core tasks, actions, and decisions users perform at each stage of the journey. | 📁 | 🧾 | 🏛️ | 🆘 | 🧑‍💻 | 🗨️ | 🔁 | 📊 | 📝 | 🧾 | 📚 |
|  | Finalises submission tagging and applies retention rules. | Stores records in accordance with DAMF. | Ensures traceability and FoI readiness. | Supports public users via helpdesk or email. | Logs user-reported issues with portal or submission formats. | Provides real-time answers to FAQs. | Updates SOPs and comms based on user needs. | Compiles triage and handling metrics for program reporting. | Provides executive summaries to BPR team. | Prepares audit-ready archive exports. | Captures lessons learned for future rounds. |
| **Service Improvements**Enhancements to systems, processes, or tools that support a better experience or reduce risk. | 🗃️ | 📑 | 🧾 | 🧰 | 💬 | 📞 | 🛠️ | 📉 | 📤 | 📦 | 📓 |
|  | Role-based archival permissions and naming conventions. | Metadata schema aligned with DAMF catalogue. | Built-in retention and redaction rules. | Ticketing system for intake support. | Portal support chatbot for common queries. | Helpdesk scripts linked to submission states. | Update comms based on real issues reported. | Dashboard shows processing backlog and response rates. | Auto-generation of summary reports. | Export to long-term archive with metadata. | Internal retrospective template available. |
| **User Experience**How the user feels or reflects on the process — their perceptions, needs, and satisfaction at each stage. | 🗂️ | 🔐 | 🧾 | 🧑‍🚒 | 💬 | 📞 | 🛠️ | 📊 | 🧠 | 📦 | 🧾 |
|  | *“The recordkeeping setup makes it easier to show compliance.”* | *“We’ve finally aligned metadata with our retention rules.”* | *“We’re audit-ready — that’s peace of mind.”* | *“our team knows how to help submitters quickly.”* | *“The FAQ bot helped resolve most queries instantly.”* | *“Having scripts helps keep things consistent.”* | *“We’re improving our help docs from actual issues.”* | *“We’re getting insight into triage bottlenecks.”* | *“Reporting is now just a few clicks.”* | *“Archival is automatic — no more last-minute scrambles.”* | *“We’ve documented key lessons already.”* |

   6. 

| Intake Monitoring | Triage & Escalation | Routing & SME Review | Redaction & Records | Closeout & Archival |
| ----- | ----- | ----- | ----- | ----- |
| **Evidence** |  |  |  |  |
| Dashboard showing live volume Submission source log | Metadata tags Flag indicators (e.g. ICIP, campaign, privacy) | Routing logs SME assignment history | Redaction flags Review comments Consent terms | Triage completion log Submission archive ID list |
| **Journey** |  |  |  |  |
| Opens dashboard and begins monitoring intake activity | Reviews tags and flags Escalates risks | Assigns submissions to SMEs or redaction team | Verifies redaction and final status Applies storage tag | Closes out open items and compiles final report |
| **Touchpoints** |  |  |  |  |
| 🖥️ Triage dashboard 📊 Submission tracker | ⚠️ Risk flag panel 🗂️ Submission viewer | 🧾 SME work queue 📧 Assignment log | ✂️ Redaction tool 📁 Metadata editor | 📦 Archive dashboard 📄 Submission summary generator |
| **Employee Actions** |  |  |  |  |
| Refreshes dashboards and validates system integrity | Manually checks flagged items Applies judgment calls | Reassigns items to reviewers based on volume/topic | Confirms legal/redaction status Updates submission metadata | Tags closed submissions for storage Prepares archival metadata export |
| **Technology** |  |  |  |  |
| Intake monitor Power BI dashboard Campaign alert rules | Auto-tagging engine Consent flag review panel | Routing ruleset editor Role-based SME queue | Redaction workflow module Consent audit trail | Records management export utility Completion status tracker |
| **Backstage Actions** |  |  |  |  |
| System triggers campaign detection logic Auto-routes priority items | Triaged submissions stored with audit trail Legal/ICIP escalations logged | SME allocation workflow triggered Assignments stored in metadata | Redaction applied and recorded Publication flags managed | All submissions assigned final status Readied for long-term storage |
| **Supporting Processes** |  |  |  |  |
| Submission intake SOP Volume threshold alerts | Triage escalation protocol Legal & ICIP referral criteria | SME workload balancing SOP Reviewer assignment matrix | Redaction standards Publication eligibility checklist | Records retention rules Post-submission audit plan |
| **Regulations/Policies** |  |  |  |  |
| Records Management Act Water Act (s51 compliance) | Privacy Act 1988 FOI Act 1982 ICIP Protocols | Information Governance Framework Internal Workflow Policy | MDBA Redaction Guidelines Data Sovereignty Protocols | DAMF alignment National Archives Disposal Authorities |
| **Design Features** |  |  |  |  |
| Live triage dashboard Auto-tagging by theme/source Campaign detection | Metadata-based routing Inline flag review with escalation triggers | Role-based SME queues Escalation tracking per submission | Redaction layer with comment history Publication status field | Completion log per submission Metadata mapping for archive export |

7. **Platform oversight**

   1. **Overview**

The Platform oversight service type encompasses the governance, configuration, and technical maintenance of the systems that enable the submissions process. It is responsible for ensuring that the digital infrastructure used to support intake, processing, storage, and reporting is secure, performant, and aligned with MDBA's enterprise architecture and data governance standards.

This service type is essential for operational resilience, compliance with internal ICT policies, and ongoing performance monitoring. It includes authentication, access control, infrastructure provisioning, system integration, and real-time service availability monitoring. Platform oversight acts as the behind-the-scenes enabler that ensures the reliability, scalability, and safety of the user and staff experience.

**Note:** Scope Clarification

This service type covers:

○	Technical configuration, hosting, access control, and monitoring of the submission system.  
○	Integration with internal MDBA platforms (e.g. Microsoft stack, Power BI, SharePoint).  
○	Audit trails, redaction infrastructure, and data sovereignty enforcement.  
○	Incident management, performance reporting, and post-process reviews.

This service type does not cover:

○	Public or staff-facing workflows or dashboards  
(*covered in [**Process Coordination**](#bookmark=id.u8u9holqw271)*).  
○	The thematic analysis of submission content  
(*covered in [**Strategic Synthesiser**](#bookmark=id.cip8me6iz8o8)*).  
○	Legal review or redaction decision-making  
(*covered in [**Compliance Assurance**](#bookmark=id.1qthm6v616sh)*).  
○	User engagement or submission preparation  
(*covered in [**Engaged Contribution**](#bookmark=id.tp3r9l5pgfwv)*).

**Table 9: Process Coordination – Service Overview Table**

| Question | Description |
| :---- | :---- |
| **What is the purpose of the service type?** | Platform Oversight ensures that the submission system functions consistently, securely, and in alignment with MDBA’s technical and compliance expectations. It supports the safe collection, processing, and storage of submission data across the lifecycle and provides the auditability, privacy, and technical reliability needed to meet regulatory, public trust, and operational efficiency goals. This service ensures the system is not only functional but defensible and sustainable. |
| **Who will benefit and why?** | ICT custodians, system administrators, data governance staff, and platform integrators benefit from this service through structured controls and monitoring tools that reduce risk and enable rapid response to performance issues. The broader organisation benefits through enhanced security, reduced service outages, and strong defensibility in FOI and audit scenarios. Contributors and reviewers benefit indirectly from a stable, accessible, and secure system they can trust. |
| **Who will access the service type? (User Personas)** | Primary access will be limited to: Platform Guardian – Oversees the end-to-end technical operation of the platform, including access control, security, and performance. ICT Support Analyst – Supports issue resolution, system health monitoring, and incident triage. Enterprise Architect – Ensures alignment with EA principles, DAMF, and internal IT governance. Compliance Custodian (technical role) – Verifies platform meets retention and privacy requirements. |
| **What are the primary channels for the service?** | This service operates through: Infrastructure configuration platforms (e.g. Azure, Convalens, SharePoint Online, Power Platform). Monitoring dashboards with uptime alerts, error logs, and telemetry insights. Admin portals for managing roles, permissions, and retention policies. Audit logs and incident response workflows. Internal documentation tools for storing SOPs, configuration registers, and version control records. |
| **What technology is expected to be required to support the service?** | Platform Oversight will require: Microsoft Azure tenancy with secure cloud storage and regional sovereignty controls. SSO/MFA authentication integrated via Azure Active Directory. Audit log tracking and export capability for records compliance. Uptime and error monitoring via Power Platform admin centre or integrated observability tool. Configurable access control logic mapped to submission roles. Post-incident review tooling to support continuous improvement. |

2. **Platform oversight Journey (Part 1: Setup, Access & Monitoring)**

| Platform oversight | Platform Configuration |  |  | Access & Integration |  |  |  | System Monitoring |  |  |  |
| :---- | ----- | ----- | ----- | ----- | ----- | ----- | ----- | ----- | ----- | ----- | ----- |
| **Key Activities**The core tasks, actions, and decisions users perform at each stage of the journey. | 🏗️ | ⚙️ | 🗂️ | 🔐 | 🧩 | 🔗 | 📥 | 📊 | 🧭 | 🛎️ | 📌 |
|  | Builds and deploys secure infrastructure with appropriate role-based access and environments. | Aligns deployment with MDBA Enterprise Architecture and DAMF. | Enables audit and change tracking across system components. | Sets authentication protocols using Microsoft SSO and MFA. | Enables access control by role and sensitivity. | Integrates with internal systems (e.g. D365, Power BI). | Manages ingest processes and endpoints. | Monitors traffic, uptime, error logs, and ingestion flows. | Sets alert thresholds for system errors. | Flags unexpected usage patterns. | Logs incidents for review. |
| **Service Improvements**Enhancements to systems, processes, or tools that support a better experience or reduce risk. | 🧱 | 🏷️ | 📚 | 🔑 | 🧮 | 🔌 | ⚙️ | 🖥️ | 🧾 | 🚨 | 🧰 |
|  | Standardised Azure-hosted architecture with pre-approved infrastructure-as-code templates. | Configurable access logs with retention controls. | Alignment with MDBA ICT stack and governance model. | Federated identity and conditional access policies. | Tiered role-based permissions with read/write/report separation. | APIs for secure system-to-system transfer. | Scalable ingest and validation pipelines. | Live monitoring dashboard with drill-down views. | Scheduled health checks and status reports. | Alerts for volume spikes, downtime, or authentication errors. | Incident triage and root cause analysis tools. |
| **User Experience**How the user feels or reflects on the process — their perceptions, needs, and satisfaction at each stage. | 🧑‍💻 | 🧠 | 🧾 | 🙅‍♂️ | 🧍‍♂️ | 🔐 | 🧰 | 🧮 | 🔍 | 📢 | 🔧 |
|  | *“The infrastructure is finally clean, compliant, and scalable.”* | *“We followed EA principles — no custom snowflakes.”* | *“It’s reassuring to know the audit trails are complete.”* | *“SSO and MFA make secure login seamless.”* | *“I can grant and revoke access quickly by role.”* | *“Everything plugs in without a fight.”* | *“We’ve got strong ingest and data handling rules.”* | *“I can see errors before they become outages.”* | *“Early warnings helped us catch a misconfigured field.”* | *“The alert was triggered before users were affected.”* | *“We’ve captured logs for the post-mortem.”* |

3. **Platform oversight Journey (Part 2: Security, Incidents & Evaluation)**

| Platform oversight | Security & Privacy Enforcement |  |  | Incident Response |  |  |  | Post-Process Review |  |  |  |
| :---- | ----- | ----- | ----- | ----- | ----- | ----- | ----- | ----- | ----- | ----- | ----- |
| **Key Activities**The core tasks, actions, and decisions users perform at each stage of the journey. | 🔐 | 🧾 | 🕵️ | 🚨 | 🧯 | 🧑‍💻 | 🔁 | 📋 | 📈 | 📤 | 🧾 |
|  | Enforces encryption at rest and in transit. | Applies IP restrictions and device management. | Conducts regular access audits and data flow checks. | Responds to errors, downtime, and threats. | Patches and remediates root causes. | Coordinates with Legal and ICT on escalation. | Logs outcomes and actions taken. | Reviews telemetry and system usage across the submission window. | Generates system performance metrics. | Delivers post-cycle infrastructure updates. | Archives logs and lessons for future reviews. |
| **Service Improvements**Enhancements to systems, processes, or tools that support a better experience or reduce risk. | 🔐 | 📜 | 📊 | 🆘 | 🔧 | 🧑‍⚖️ | 🪵 | 📈 | 📑 | 📤 | 🧠 |
|  | Encryption policy applied across storage, portal, and submission archive. | Device-based policy enforcement. | Monthly access report auto-generated. | System alerts and escalation playbooks. | Automated patches with downtime logging. | Integration with legal review workflows. | Structured post-incident logs. | Weekly and end-of-window usage reports. | Exportable system performance dashboards. | Change log reviewed after consultation closes. | ICIP and Privacy exception tracking reviewed. |
| **User Experience**How the user feels or reflects on the process — their perceptions, needs, and satisfaction at each stage. | 🧘‍♂️ | 🧱 | 👀 | 🧯 | 🛠️ | 👨‍⚖️ | 📜 | 📊 | 🧠 | 🧾 | 📚 |
|  | *“I’m confident the data is protected end-to-end.”* | *“Access feels secure without being restrictive.”* | *“I can see what changed, when, and why.”* | *“When something goes wrong, we know exactly what to do.”* | *“We had it patched within the hour.”* | *“We triggered legal review without delay.”* | *“We learned something from every incident.”* | *“I know what parts of the platform were used and where we struggled.”* | *“The usage dashboard showed how we scaled.”* | *“our infrastructure is better than last time.”* | *“We’re building an evidence base for next round.”* |

   8. 

| Platform Preparation | Monitoring & Incident Response | Support & Resolution | Audit & Compliance | Post-Process Optimisation |
| ----- | ----- | ----- | ----- | ----- |
| **Evidence** |  |  |  |  |
| Readiness checklist Platform deployment log | Uptime dashboard Error alert log | Incident ticket Upload failure report | Audit trail export Consent metadata summary | Post-process review pack Performance report |
| **Journey** |  |  |  |  |
| Verifies readiness of infrastructure and core systems | Monitors load and availability Responds to alerts | Investigates issues Coordinates resolution | Exports logs Confirms compliance against policy | Reviews system usage patterns Identifies improvement areas |
| **Touchpoints** |  |  |  |  |
| 🖥️ Admin portal 🧾 Infrastructure logbook | 📊 Monitoring dashboard 🚨 Alert email | 🛠️ ITSM ticketing system 📞 Support team call | 🧾 Audit dashboard 📤 Metadata extractor | 📈 Performance report 🧠 Lessons learned review |
| **Employee Actions** |  |  |  |  |
| Validates authentication and role setup Checks storage capacity | Diagnoses incidents Escalates to vendors or internal teams | Applies fix or workaround Updates incident record | Runs report exports Tags content for legal retention | Participates in retrospective Logs system insights |
| **Technology** |  |  |  |  |
| Azure AD for SSO/MFA Blob storage monitor Access control panel | Power Platform Admin Centre Uptime monitor Telemetry services | Issue tracking platform Upload and validation logging | Log export engine Governance tagging Retention scheduler | Usage analytics dashboard Lessons-learned wiki |
| **Backstage Actions** |  |  |  |  |
| Deploys templates Enables monitoring thresholds | Logs incident ID and resolution path Sends status update | Applies retention rules or emergency patches Records fix | Updates configuration registry Archives logs securely | Contributes to platform improvement recommendations |
| **Supporting Processes** |  |  |  |  |
| ICT Release Checklist Azure Subscription Policy | Incident Response SOP Performance Threshold Policy | Vendor escalation agreement Issue escalation flow | DAMF compliance framework PIA protocol enforcement | Post-mortem review template Service Performance Criteria |
| **Regulations/Policies** |  |  |  |  |
| MDBA EA Principles Records Management Act | DAMF Privacy Act Cybersecurity Protocols | Support SLA Data Security Classification Policy | FOI Act 1982 Records Disposal Authorities | EA Continuous Improvement Standard ICT Maturity Guidelines |
| **Design Features** |  |  |  |  |
| SSO/MFA login Regional storage compliance Role-based access | Live dashboards with alert triggers Telemetry insights | Auto-ticket creation on failure File-type-aware upload tracking | Consent traceability Exportable audit logs Retention tagging | System usage analytics Configuration diff tool Improvement tracking |

9. **Compliance Assurance**

   1. **Overview**

The Compliance Assurance service type ensures that all legal, regulatory, and ethical obligations are met throughout the submission process lifecycle. This includes the management of consent, privacy, FoI, intellectual and cultural property (ICIP), defamation risk, and publication eligibility. It involves both proactive safeguards and reactive escalation pathways to ensure that submission handling is legally defensible and ethically sound.

This service type operates in close coordination with Process Coordination, Platform oversight, and Legal Services, and is critical to upholding MDBA’s obligations under the Water Act 2007, Privacy Act 1988, FoI Act 1982, and MDBA’s ICIP Protocols. It protects both contributors and the Authority by ensuring content is appropriately redacted, escalated, withheld, or published.

**Note:** Scope Clarification

This service type covers:

Consent model design and verification.  
○	ICIP and privacy risk identification and escalation.  
○	Legal assessment of content for publication or redaction.  
○	Retention and reuse risk management.  
○	FoI defensibility, legislative compliance, and audit support.

This service type does not cover:

○	Public portal design or consent capture UI (*covered in [**Engaged Contribution**](#bookmark=id.tp3r9l5pgfwv)*).  
○	Data storage and platform availability (*covered in [**Platform oversight**](#bookmark=id.tt80l95em7eq)*).  
○	Thematic analysis or insight extraction (*covered in [**Strategic Synthesiser**](#bookmark=id.cip8me6iz8o8)*).  
○	Initial triage and workflow management (*covered in [**Process Coordination**](#bookmark=id.u8u9holqw271)*).

**Table 10: Compliance Assurance – Service Overview Table**

| Question | Description |
| :---- | :---- |
| **What is the purpose of the service type?** | Compliance Assurance ensures that submissions are handled in accordance with all applicable legal and ethical requirements. It enables legal defensibility, protects the rights of contributors (especially where consent or cultural protocols apply), and ensures MDBA’s risk exposure is actively managed. This includes validating the scope of submissions, managing redaction or suppression of sensitive content, and documenting decision-making in case of legal review, FoI requests, or public inquiry. |
| **Who will benefit and why?** | Legal officers, privacy advisors, records managers, and governance staff benefit directly by having consistent, documented processes to assess and manage risk. Contributors benefit indirectly from improved data protection, respect for cultural rights, and visibility into how their input is treated. The MDBA benefits through reduced legal risk, improved defensibility in publication decisions, and increased trust in its consultation practices — particularly from First Nations and other culturally sensitive groups. |
| **Who will access the service type? (User Personas)** | This service is primarily used by: **Compliance Custodian** – Leads oversight of privacy, consent, ICIP, redaction, and FoI handling. **Legal Advisor** – Provides authoritative guidance on risks, legislative interpretation, and publication eligibility. **Privacy officer** – Ensures that consent options and personal information are handled in line with policy and law. **Records and Governance officer** – Manages defensibility and audit trail. |
| **What are the primary channels for the service?** | Compliance Assurance operates through: **Legal escalation workflows** embedded in submission processing tools. **Consent registry** linked to each submission record. **ICIP tagging and cultural metadata** dashboards for risk identification. **Redaction and publication review** interfaces used prior to content release. **Audit logs, policy repositories, and legislative interpretation guidance** stored in internal knowledge systems. |
| **What technology is expected to be required to support the service?** | Required technologies include: **Consent management engine** with metadata fields and expiry/revocation logic. **Legal review and annotation** tools allowing redaction, flagging, and classification. **ICIP-aware tagging system** integrated into triage and processing workflows. **Redaction toolset** embedded within the publishing layer to suppress personal or cultural information. **Audit trail and FoI response** toolkit to produce defensibility records for legal and parliamentary scrutiny. |

2. **Compliance Assurance Journey (Part 1: Pre-Lodgement & Review)**

| Compliance Assurance | Pre-launch Legal & Policy Setup |  |  | Submission Monitoring |  |  |  | Consideration & Escalation |  |  |  |
| :---- | ----- | ----- | ----- | ----- | ----- | ----- | ----- | ----- | ----- | ----- | ----- |
| **Key Activities**The core tasks, actions, and decisions users perform at each stage of the journey. | 🧾 | ⚖️ | 📃 | 🔍 | 🚩 | 🛡️ | 🧾 | 🧑‍⚖️ | 🪶 | 🧮 | 📁 |
|  | Reviews submission guidelines, consent language, and redaction rules. | Ensures alignment with Water Act, Privacy Act, FoI, ICIP guidelines. | Confirms triage rules cover legal and ethical risks. | Reviews submissions flagged for ICIP, privacy, defamation, or copyright risks. | Identifies campaign material and sensitive content. | Evaluates cultural and personal identifiers for risk. | Documents recommendations and redaction notes. | Advises on whether a submission meets "consideration" under s51. | Confirms legal thresholds for public interest or publication limits. | Reviews how campaign vs. unique input is weighted. | Prepares memo or internal legal decision trail. |
| **Service Improvements**Enhancements to systems, processes, or tools that support a better experience or reduce risk. | 📚 | 📜 | 📏 | 🧮 | ⚠️ | 🔐 | 📋 | ⚖️ | 📑 | 📊 | 🗂️ |
|  | Consent and ICIP language reviewed pre-launch. | Pre-cleared legal templates and escalation rules. | Redaction SOP tied to types of risk (privacy, defamation, etc.). | Privacy/ICIP flags auto-applied to submissions with media or key phrases. | Submission dashboard filters for flagged content. | Consent records embedded in submission metadata. | Legal checklist integrated into SME review flow. | Centralised legal dashboard for real-time advice. | Draft position statements for complex content. | Campaign flag logic visible to legal teams. | Linked case notes to internal file registry. |
| **User Experience**How the user feels or reflects on the process — their perceptions, needs, and satisfaction at each stage. | 🧘 | 👨‍⚖️ | 🧠 | 🧑‍💼 | ⚠️ | 😰 | 📝 | 🧑‍⚖️ | 🧐 | 🔎 | 📜 |
|  | *“We’ve embedded legal safeguards right from the start.”* | *“We’re confident the guidelines hold up under scrutiny.”* | *“There’s no ambiguity in how we escalate sensitive content.”* | *“I can review flagged submissions quickly and trace decisions.”* | *“I see the risks as they come in — no surprises.”* | *“We’re not missing ICIP or defamation risks anymore.”* | *“All my legal notes are tracked in one place.”* | *“I can defend our decisions if challenged — that’s critical.”* | *“We’ve documented our rationale clearly.”* | *“We can explain how campaign input is handled fairly.”* | *“It’s all discoverable in the audit trail.”* |

   10. 

       1. **Compliance Assurance Journey (Part 2: Publication & Legal Finalisation)**

| Compliance Assurance | FoI, Privacy & Redaction Planning |  |  | Publication Decision Support |  |  |  | Audit, Records & Legal Traceability |  |  |  |
| :---- | ----- | ----- | ----- | ----- | ----- | ----- | ----- | ----- | ----- | ----- | ----- |
| **Key Activities**The core tasks, actions, and decisions users perform at each stage of the journey. | 📚 | 🧾 | 🚫 | 📢 | 📝 | 🗞️ | 🧾 | 📂 | 🧾 | 🔍 | 📋 |
|  | Prepares FoI strategy including exemptions, redactions, and exclusions. | Applies consent choices for ICIP and personal submissions. | Ensures restricted content is handled appropriately. | Supports publication approval decisions with legal advice. | Validates redaction of names, contact details, sensitive media. | Reviews campaign content prior to publishing. | Approves final outputs. | Archives legal decisions and audit logs. | Maintains submission audit trail. | Provides defensibility evidence if challenged. | Updates legal risk register. |
| **Service Improvements**Enhancements to systems, processes, or tools that support a better experience or reduce risk. | 🧾 | 🔐 | 🛑 | 📣 | ✂️ | 📰 | ✅ | 📜 | 📁 | ⚖️ | 🧾 |
|  | Redaction logic embedded in publishing workflow. | Consent tags linked to publication settings. | Auto-redaction for known fields. | Legal sign-off step built into publication review. | Defamation and privacy filters with manual override. | Media content split into public/redacted versions. | Confirmation prompts before release. | Audit notes appended to record. | FoI-ready archive bundles. | Legal defensibility tracker. | Risk and compliance review template. |
| **User Experience**How the user feels or reflects on the process — their perceptions, needs, and satisfaction at each stage. | 🧑‍⚖️ | 🔐 | 🤫 | 🧏 | ✂️ | 📰 | 🧾 | 🧠 | 📦 | 🧮 | 📜 |
|  | *“We’ve built a publishing process that protects everyone involved.”* | *“I know what’s private and how to respect that.”* | *“The redaction tools make the job faster and cleaner.”* | *“I trust the public won’t see anything they shouldn’t.”* | *“Sensitive content is clearly flagged.”* | *“We control how much campaign content is published.”* | *“I approve it with confidence.”* | *“our decisions are documented for anyone who asks.”* | *“The archive is defensible if challenged.”* | *“I know our approach meets compliance.”* | *“We’ve captured everything for future reference.”* |

| Review & Risk Identification | Legal Escalation & Advice | Consent Verification & Redaction | Publication & Withholding Decision | Audit & Records Integration |
| ----- | ----- | ----- | ----- | ----- |
| **Evidence** |  |  |  |  |
| Flagged submission ICIP or privacy indicators | Legal review notes Case classification | Consent record ICIP flags Redaction tool | Publication status tag Release approval record | FOI tracker Audit log with redaction decision history |
| **Journey** |  |  |  |  |
| Opens flagged item and reviews metadata | Consults legal/ICIP experts and weighs publication risk | Verifies consent scope and timeframe | Applies publication rules and updates system | Confirms audit trail is complete and supports downstream use |
| **Touchpoints** |  |  |  |  |
| ⚠️ Triage dashboard 📄 Submission viewer | 📧 Email chain 📁 Internal consultation notes | ✅ Consent metadata viewer ✂️ Redaction form | 🛑 Publication toggle 📑 Withholding rationale log | 📤 Audit export 📚 FOI documentation folder |
| **Employee Actions** |  |  |  |  |
| Reviews tags and opens associated media | Engages legal/ICIP support teams and documents advice | Reads consent form and applies eligibility filters | Approves redaction or blocks publication | Uploads evidence trail and closure tag |
| **Technology** |  |  |  |  |
| Submission triage dashboard Metadata explorer | Legal comment layer Review sharing tool | Consent registry ICIP tagging engine | Redaction engine Publishing eligibility control panel | FOI management system Audit export service |
| **Backstage Actions** |  |  |  |  |
| Retrieves submission data and verifies flag origin | Routes to internal SME reviewers for complex interpretation | Tracks metadata revisions and expiry windows | Applies redaction overlay Locks submission status | Attaches documentation to compliance archive |
| **Supporting Processes** |  |  |  |  |
| Risk flagging protocol ICIP and privacy escalation procedure | Legal/ICIP review SOP Redaction decision log format | Consent lifecycle policy ICIP metadata handling rules | Publication rules matrix Withholding criteria framework | FOI response toolkit Audit trail checklist |
| **Regulations/Policies** |  |  |  |  |
| Water Act s51(2) Privacy Act ICIP Protocols | FOI Act 1982 Defamation Law CARE Principles | Consent Policy Publication Exemption Guidelines | Public Disclosure Policy Records Classification Policy | Records Management Act FOI Recordkeeping Framework |
| **Design Features** |  |  |  |  |
| Visual risk indicators Inline metadata panel | Comment/annotation layer for legal reviewers | Time-bound consent review ICIP alerting engine | Toggle for public/internal view Publication lock | Full audit log with timestamped events FOI response generator |

11. **Insight Generation**

    1. **Overview**

The Insight Generation service type supports the generation of insights from submissions and ensures that the voices, evidence, and experiences gathered during consultation are meaningfully interpreted, reported, and communicated. This includes identifying common themes, producing summaries, informing internal policy discussions, and preparing public reports such as *“What We’ve Heard”*.

This service type operates at the intersection of analysis, communication, and decision support. It helps transform a high volume of submissions — often diverse in format, tone, and content — into structured insights that can be clearly linked to Basin Plan Review decision-making. It provides the narrative evidence base that ensures transparency and accountability in how submissions are considered.

Note: Scope Clarification

This service type covers:

○	Thematic coding, sentiment analysis, and trend identification.  
○	Preparation of public reports and executive briefings.  
○	Development of visuals, summaries, quotes, and supporting artefacts.  
○	Maintenance of traceability between submissions and insights.  
○	Post-review evaluation and knowledge transfer for future consultation.

This service type does not cover:

○	The submission platform, collection interface, or consent process  
(*covered in [**Engaged Contribution**](#bookmark=id.tp3r9l5pgfwv)*).  
○	Triage, routing, and SME workflows (*covered in [**Process Coordination**](#bookmark=id.u8u9holqw271)*).  
○	Platform-level infrastructure or availability (*covered in [**Platform Oversight**](#bookmark=id.tt80l95em7eq)*).  
○	Legal redaction or publication risk decisions  
(*covered in [**Compliance Assurance**](#bookmark=id.1qthm6v616sh)*).

**Table 11: Insight Generation \- Service Overview Table**

| Question | Description |
| :---- | :---- |
| **What is the purpose of the service type?** | The Insights Generation service enables the MDBA to extract meaningful insights from thousands of submissions and present those insights in a way that is credible, traceable, and accessible. It ensures that the Basin Plan Review process is not only participatory but also deliberative — where public input informs decision-making. This service underpins transparency, strengthens the link between community voice and final policy decisions, and ensures all perspectives are represented in a structured and defensible manner. |
| **Who will benefit and why?** | Internal policy teams, executive decision-makers, communications officers, and community engagement teams all benefit from timely and structured access to submission themes. Contributors also benefit — often indirectly — by seeing their views reflected in published summaries, quotes, or thematic representations. By surfacing what was heard and how it influenced outcomes, the Strategic Synthesiser helps build legitimacy, manage expectations, and ensure community trust in the Basin Plan Review process. |
| **Who will access the service type? (User Personas)** | The key personas using this service include: **Strategic Synthesiser** – Leads the translation of submissions into insights and summaries. **Executive Decision-Maker** – Uses thematic briefings and visual dashboards to inform key positions. **Communication Specialist** – Crafts narratives, publishes reports, and supports broader understanding of results. **Policy Analyst** – Aligns insights to decision frameworks and strategic planning processes. |
| **What are the primary channels for the service?** | The service is delivered through: **Internal dashboards and insight workspaces** (e.g. Power BI, SharePoint, MS Teams.). **What We’ve Heard reporting toolkits** with built-in templates for narrative, charts, and quotes. **Submission influence log** showing how particular submissions or themes impacted outcomes. **Briefing packs and decision memos** linked to underlying submission themes. **Post-review evaluation forms** to capture insight quality, gaps, and learning for next cycle. |
| **What technology is expected to be required to support the service?** | Required technologies include: **Tagging and classification engines** to group submissions by topic, sentiment, or archetype. **Thematic dashboarding tools** (e.g. Power BI) with filtering and drill-down capabilities. **Submission-to-insight mapping register** to maintain traceability. **Narrative and quote repository** for inclusion in reports. **Automated report generation tools** to support *“What We’ve Heard”* and executive briefing products. **Knowledge archive** to support future reuse and longitudinal analysis. |

2. **Strategic Synthesiser Journey (Part 1: Data Intake & Insights Generation)**

| Insight Generation | Data Preparation |  |  | Theme Analysis & Insights |  |  |  | What We've Heard Reporting |  |  |  |
| :---- | ----- | ----- | ----- | ----- | ----- | ----- | ----- | ----- | ----- | ----- | ----- |
| **Key Activities**The core tasks, actions, and decisions users perform at each stage of the journey. | 🧹 | 📊 | 📂 | 🧠 | 🧾 | 🔍 | 🏷️ | 📝 | 📈 | 📎 | 📑 |
|  | Accessed triaged, de-identified submission data. | Reviews campaign vs. individual submissions. | Checks metadata quality and ICIP tagging. | Identifies common themes and patterns. | Groups submissions by topic, region, or archetype. | Reviews content for sentiment or intensity. | Tags submissions to support topic clustering. | Drafts thematic summaries for internal and public reporting. | Develops charts and visual representations. | Selects quotes, statistics, and stories. | Aligns findings to Discussion Paper themes. |
| **Service Improvements**Enhancements to systems, processes, or tools that support a better experience or reduce risk. | 🧼 | 📋 | 🧾 | 🧠 | 🏷️ | 📐 | 🧮 | 🧾 | 📊 | 🖼️ | 📘 |
|  | Cleansing scripts to filter and standardise content. | Campaign auto-flagging for context weighting. | Metadata schema validated before ingestion. | AI-assisted tagging and similarity scoring. | Configurable taxonomies based on submission content. | Sentiment detection enabled by NLP model. | Submission heatmaps and keyword tagging. | *“What We’ve Heard”* templates pre-configured. | Power BI dashboards linked to submissions. | Snippet and quote repository. | Report templates aligned to key topics. |
| **User Experience**How the user feels or reflects on the process — their perceptions, needs, and satisfaction at each stage. | 🧑‍💼 | 👓 | 📦 | 🧠 | 🧩 | 🔬 | 🧾 | 🗣️ | 📊 | ✍️ | 📖 |
|  | *“The dataset is clean and consistent — a rare luxury.”* | *“I can instantly filter campaign content.”* | *“Tagging is already done — I can dive straight into the data.”* | *“Emerging topics are clear across multiple submissions.”* | *“It’s easy to segment responses by region or interest.”* | *“The sentiment layer is helpful for prioritising.”* | *“I can apply filters and see results instantly.”* | *“The summaries are grounded in actual quotes.”* | *“The dashboards are dynamic and credible.”* | *“It’s easy to find illustrative examples.”* | *“I can write this report in a day, not a week.”* |

3. **Strategic Synthesiser Journey (Part 2: Executive Support & Evaluation)**

| Insight Generation | Executive Briefings & outputs |  |  | Evaluation & Feedback Loops |  |  |  | Knowledge Transfer & Closeout |  |  |  |
| :---- | ----- | ----- | ----- | ----- | ----- | ----- | ----- | ----- | ----- | ----- | ----- |
| **Key Activities**The core tasks, actions, and decisions users perform at each stage of the journey. | 📋 | 📣 | 🧠 | 🔁 | 📈 | 📬 | 🧭 | 📚 | 📤 | 🧾 | 🧠 |
|  | Prepares briefing packs and talking points for MDBA Executive. | Presents findings to internal stakeholders. | Distils insights into policy-aligned narratives. | Participates in post-submissions evaluation. | Tracks coverage and influence of submissions in reporting. | Reviews what insights influenced final report. | Identifies gaps in engagement or submissions. | Packages knowledge for future use or reuse. | Archives dashboards, reports, and code. | Transfers outputs to next phase or program. | Documents insights missed and lessons learned. |
| **Service Improvements**Enhancements to systems, processes, or tools that support a better experience or reduce risk. | 📂 | 📢 | 🧭 | 🔍 | 📈 | 📑 | 🧮 | 🗃️ | 📥 | 🧷 | 🧾 |
|  | Auto-generated briefing templates with chart-ready data. | Shareable insight reports for Exec and Comms. | Executive narrative builder with submission trace links. | Feedback prompts from Exec for insight refinement. | Dashboard activity tracking to gauge relevance. | “Influence log” for key submission impacts. | Final submission–decision traceability map. | Structured storage of insight assets. | Summary archive accessible for reuse. | output handover checklist. | Insight synthesis retrospectives. |
| **User Experience**How the user feels or reflects on the process — their perceptions, needs, and satisfaction at each stage. | 🗂️ | 🎤 | 🧠 | 🧑‍🔬 | 📊 | ✍️ | 📎 | 📘 | 🧳 | 🔁 | 🧾 |
|  | *“I can export everything I need in minutes.”* | *“The Exec are engaged because the story is clear.”* | *“We’re not just summarising — we’re influencing.”* | *“We reviewed the report and could immediately improve it.”* | *“We saw which ideas landed and which didn’t.”* | *“We documented who influenced what.”* | *“I could trace a comment through to action.”* | *“The wrap-up pack will help next year’s team.”* | *“All my dashboards are archived and shareable.”* | *“We’ve transitioned everything smoothly.”* | *“We’re capturing insights better each round.”* |

| Data Preparation & Access | Insight Generation & Clustering | Narrative Construction & Reporting | Review & Approval | Knowledge Transfer & Evaluation |
| ----- | ----- | ----- | ----- | ----- |
| **Evidence** |  |  |  |  |
| Tagged submission dataset Metadata filters | Theme clusters Sentiment scores Geographic breakdowns | Quotes list Draft “What We’ve Heard” summary | Stakeholder review comments Comms and Legal feedback | Insight tracker Lessons learned log |
| **Journey** |  |  |  |  |
| Loads dataset and begins thematic exploration | Identifies trends and selects relevant insights | Writes narrative and selects supporting data | Shares outputs for approval and responds to comments | Captures insight gaps and prepares for reuse |
| **Touchpoints** |  |  |  |  |
| 🗃️ Data portal 🧭 Metadata explorer | 📊 Dashboard filters 📍 Theme mapper | 📝 Report builder 📎 Quote selector | 🧑‍⚖️ Review round 🗣️ Feedback loop | 🧠 Evaluation form 📚 Internal archive |
| **Employee Actions** |  |  |  |  |
| Reviews tags and cross-checks metadata consistency | Uses NLP tools or filters to identify clusters | Drafts insights, links quotes, and formats visual elements | Revises draft based on legal, comms, or executive feedback | Completes evaluation template and uploads insights |
| **Technology** |  |  |  |  |
| Power BI dashboard Searchable submission repository | Topic modelling tool Sentiment analyser | Report generator Quote library | Collaboration workspace Redaction-integrated preview | Archive tagging tool Insights dashboard |
| **Backstage Actions** |  |  |  |  |
| Cleans data and ensures readiness post-triage | Applies logic to group by topic, region, or archetype | Flags quotes requiring redaction or ICIP review | Logs approval status and decision notes | Attaches tags for reuse and cross-program learning |
| **Supporting Processes** |  |  |  |  |
| Submission data readiness SOP Theme curation guidelines | Cluster validation protocol Insight validation matrix | Report writing framework WWHR style and tone guide | Publication approval workflow Redaction and ICIP clearance process | Post-review debrief plan Insight impact tracking |
| **Regulations/Policies** |  |  |  |  |
| Privacy Act ICIP Protocols Data Governance Manual | Public Reporting Standards Review Consideration Guidelines | FOI Publication Policy Consent Use Policy | Legal Review SOP Records Management Guidelines | MDBA Knowledge Management Strategy |
| **Design Features** |  |  |  |  |
| Thematic dashboard with drilldown Metadata tagging controls | Configurable filters Quote tagging engine | Template-driven report sections Consent-aware content preview | Collaborative review with ICIP/legal alerts Publishing permissions logic | Archive-ready insights with tagging Insight reuse interface |

4. **Operating Model**

The operating model defines the roles, governance arrangements, and accountability structures that will support the effective delivery and sustainable operation of the Basin Plan Review (BPR) Submissions Process. It ensures that responsibility for both process and platform is clearly delineated, and that the model supports compliance, adaptability, and continuous improvement.

1. **Governance Structure**

A tiered governance structure ensures alignment with MDBA’s enterprise architecture, policy obligations, and program-level objectives.

| Group | Responsibility |
| :---- | :---- |
| Senior Responsible Officer | Accountable for end-to-end success of the submissions process, including cross-functional coordination. |
| Steering Group | Oversight of scope, risk, interdependencies, and strategic alignment across BPR program activities. |
| Architecture Reference Group (ARG) | Ensures technical design aligns with MDBA’s EA principles and technology strategy. Ensure compliance with intent and purpose |

2. **Delivery Roles**

Day-to-day delivery of the service relies on a small number of defined roles with clear ownership across content, compliance, technology, and reporting.

| Role | Function |
| :---- | :---- |
| Submission Manager | Oversees end-to-end workflow including intake, triage, routing, and feedback cycles. |
| Privacy Lead | Ensures personal information handling and consent mechanisms comply with the Privacy Act. |
| ICIP Review Coordinator | Manages cultural data triggers and ICIP-related escalations; liaises with internal advisors. |
| Data and Analytics Officer | Oversees metadata quality, dashboard reporting, and insight generation. |
| Legal Advisor | Provides guidance on FOI, defamation, redaction, and publication obligations. |

3. **Ongoing Operations**

Responsibility for operating and sustaining the submissions process post-deployment is shared between the BPR and ICT teams, ensuring clarity between business process ownership and technical system stewardship.

| Domain | Responsibility |
| :---- | :---- |
| Business Process | Owned by the BPR team — responsible for content, policy settings, and stakeholder interaction. |
| System Platform | Owned by ICT — responsible for infrastructure, performance, availability, and integrations. |
| Escalation and Support | Defined escalation matrix for privacy, ICIP, technical, and policy matters. |
| Feedback Loop | User feedback is collected during and post-submission period for process refinement. |

4. **Review and Improvement**

The operating model supports a cadence of review and refinement aligned to the broader Basin Plan Review program lifecycle.

| Activity | Frequency / Trigger |
| :---- | :---- |
| **Quarterly Continuous Improvement** | Scheduled review of performance, risks, and user experience. |
| **Post-Review Analysis** | Lessons learned captured after each submissions cycle and integrated into design updates. |
| **Governance Review** | Annual reconfirmation of roles, escalation pathways, and risk frameworks. |

5. **Operating Model Overview**

The following workflow diagram illustrates the roles, responsibilities, and governance domains involved in the end-to-end operation of the Basin Plan Review submissions process. It highlights how accountability is distributed across the BPR team, ICT, and governance groups — with clear delineation between business process ownership, platform support, and compliance oversight. It also indicates where collaboration and cooperation are essential across teams to ensure cohesive delivery, coordinated risk management, and aligned decision-making throughout the BPR process lifecycle.

**Figure 2: Submissions Process Operating Model**

### **Description of Diagram** {#description-of-diagram}

| Subgraph | Participants | Focus Areas |
| :---- | :---- | :---- |
| **Governance & Oversight** | SRO, Steering Group, ARG | Strategic alignment, risk and architecture compliance |
| **Business Operations** | BPR roles (Submission Manager, Privacy, ICIP, Analytics, Legal) | Day-to-day workflow coordination, compliance, insight, and publication |
| **ICT Platform Support** | ICT operations, cybersecurity, records | Platform hosting, escalation, and DAMF-aligned records management |

6. **Decision and Escalation Responsibilities**

To support consistent decision-making and mitigate risk, the following matrix outlines who is responsible, who must be consulted, and who must be informed for key activities and scenarios within the submissions process.

**Figure 3 Decision & Escalation Responsibilities Matrix**

| Activity / Scenario | Decision Owner | Consulted | Informed |
| :---- | :---- | :---- | :---- |
| **Submission intake rules and thresholds** | Submission Manager | Privacy Lead, Legal Advisor | Steering Group, ICT Operations |
| **Redaction and withholding decisions** | Legal Advisor | ICIP Coordinator, Records Lead | Submission Manager |
| **ICIP publication consent** | ICIP Review Coordinator | Legal Advisor, Privacy Lead | Steering Group, SRO |
| **Platform incident response** | ICT Operations | Submission Manager, Security Advisor | ARG, Records Lead |
| **Change to process workflow** | BPR Process Owner | Steering Group, Legal, ICT | Architecture Reference Group |
| **Post-cycle improvement plan** | Submission Manager | Data & Analytics, Legal, Records | Steering Group, ICT |

7. **Transition to BAU and Service Ownership**

The submissions process will transition from project delivery to business-as-usual (BAU) operations following completion of system readiness and post-submission reporting.

* **Process Ownership:** Remains with the BPR Program Team, who oversee policies, user support, and reporting alignment.

* **System Ownership:** Transferred to ICT Services once stability and operational KPIs are confirmed.

* **Support Model:** First-line support via Service Desk; second-line through ICT and specialist SMEs (Legal, Privacy, ICIP).

* **Catalogue Entry:** This service will be registered as a Tier 1 ICT-supported business service in MDBA’s Service Catalogue, with defined SLA, dependencies, and ownership metadata.

  8. **Operating Assumptions**

Effective operation of the submissions process relies on the following **baseline assumptions:**

* Legal and ICIP review resources are available during peak intake and publication windows.

* ICT capacity supports performance scaling (5,000–10,000 submissions).

* Consent and publication rules are pre-agreed and documented before intake opens.

* Service support model and escalation pathways are communicated to all operational staff.

* Records management protocols (retention, disposal, metadata) are finalised before archive handoff.

  9. **Performance and Success Measures**

To ensure the service delivers value and remains fit-for-purpose, operational performance will be monitored against key metrics. These support continuous improvement cycles and strategic alignment with MDBA’s digital and corporate objectives.

**Table 12: Performance & Success Measures**

| Metric | Target / Expectation |
| :---- | :---- |
| Submission processing time | 90% within 5 business days of receipt |
| Redaction turnaround | 100% of flagged submissions reviewed within 7 days |
| System uptime during intake window | ≥ 99.9% |
| Perceived Transparency and Process Fairness | 70%+ of respondents indicate they understood how their submission was handled and considered |
| Audit and FOI readiness | All published content supported by defensible audit trail |

10. **Service Lifecycle and Legacy Management**

The Basin Plan Review submissions process is not a permanent business service — **but it is a strategically significant national program** that warrants investment, robust design, and effective operational stewardship.

The lifecycle of this service should be deliberately managed in **three distinct phases**:

**1\. Stand-Up and Commissioning**

The service must be designed, configured, tested, and launched with confidence. This includes:

* Establishing secure infrastructure and compliance workflows

* Defining roles and onboarding staff

* Registering the service in MDBA’s catalogue with agreed SLAs

* Preparing guidance and artefacts for internal and public users

**2\. Active Operation**

During the public submission window and analysis period, the service must remain:

* Secure, available, and monitored

* Adaptable to submission volume and campaign activity

* Auditable and governed in line with FOI, ICIP, and Privacy obligations

* Supported by defined escalation and decision frameworks

**3\. Controlled Closure and Knowledge Transfer**

Once the submission cycle is complete and outputs are published:

* The system should transition into a low-maintenance archive state

* All metadata, decision logs, redactions, and ICIP indicators must be preserved

* Lessons learned, insights, artefacts, and process models must be **captured and archived** to inform the **2036 Basin Plan Review**

* The service may be mothballed but must remain discoverable and referenceable for future programs and policy reviews

The value of this service lies not just in what it delivers in 2026, but in how it supports MDBA’s institutional memory, improves the next review cycle, and reinforces MDBA’s commitment to transparency and respectful engagement.

5. **Capability Map**

The capability map outlines the business and technical capabilities required to support delivery and operation of the Basin Plan Review submissions process. It provides a foundation for planning, sourcing, and aligning resourcing across process, platform, and people — and ensures the service is sustainable, auditable, and strategically aligned.

Capabilities have been grouped into **Tier 1 Domains**, each supported by a set of **Tier 2 Capabilities**, and are mapped to phases of the submission lifecycle. This structure allows MDBA to identify dependencies, assign ownership, and assess maturity over time.

**Table 13: Tier 1 \- Domains**

| Domain | Description |
| :---- | :---- |
| **Stakeholder Engagement** | Capabilities to inform, guide, and support contributors in lodging meaningful submissions. |
| **Submission Lifecycle Management** | Core workflow capabilities that support intake, review, redaction, publication, and feedback. |
| **Risk, Privacy and Consent Handling** | Tools and workflows to manage risk, protect personal and cultural data, and ensure compliance. |
| **Analysis and Insight** | Capabilities to extract meaning from submissions and generate usable insights for reporting. |
| **Information Governance & Archiving** | Functions to classify, store, audit, and transfer submission content across its full lifecycle. |
| **Monitoring and Reporting** | Capabilities that enable real-time operational visibility, performance tracking, and insight delivery across submission, compliance, and publication workflows. These support both reactive issue management and proactive planning for transparency, equity, and effectiveness. |
| **Knowledge Stewardship & Reuse** | Capabilities to enrich, tag, and preserve strategically or culturally valuable content for future policy, research, or program use via the MDBoK knowledge system. |

**Table 14: Tier 2 \-Capabilities**

| Tier 2 Capability | Description | Supported Phase(s) |
| :---- | :---- | :---- |
| **Multi-format Submission Intake** | Ability to receive submissions in PDF, DOCX, video, audio, handwritten scan, or image format. | Collection, Intake |
| **Guided Submission and Consent Workflow** | Interactive form or upload interface that captures consent, flags ICIP, and supports accessibility. | Collection, Triage |
| **Metadata Tagging & Classification Engine** | Application of thematic, geographic, sentiment, or campaign tags to submissions. | Triage, Analysis |
| **ICIP Flagging and Redaction Workflow** | Ruleset for identifying and managing submissions containing Indigenous Cultural Intellectual Property. | Review, Publication |
| **Role-Based Access and User Identity** | Secure login, identity management, and permission models for each actor (BPR, Legal, Analyst, ICT). | All Phases |
| **Submission Status and Feedback Tracking** | Visibility for submitters and staff on status, redaction, and inclusion in reporting. | Feedback Loop |
| **Thematic and Sentiment Analysis** | Tools for surfacing issues, grouping content, and analysing patterns across submissions. | Analysis |
| **Quote and Insight Curation Tools** | Support for selecting illustrative quotes and linking submissions to reporting themes. | Analysis, Publication |
| **Audit Trail and Decision Logging** | Automated recording of who did what, when, and why — for compliance and FOI defensibility. | All Phases |
| **Records Archiving and Retention Management** | Application of DAMF rules, metadata export, and final storage handoff. | Post-Publication |
| **Campaign Activity Detection and Management** | Ability to detect templated submissions, spikes in volume, or media-driven campaigns. | Collection, Triage |
| **Dashboards and Real-Time Monitoring** | Live insights into submission volume, tag distribution, and system performance. | Intake, Review |
| **Dashboards and Real-Time Monitoring** | Provide operational visibility across submission volumes, processing throughput, redaction queues, and platform performance. Supports internal reporting and dynamic resourcing. | All Phases |
| **Submission Metrics and KPI Tracking** | Capture key indicators such as average processing time, percentage of submissions published, redaction counts, FOI readiness, and contributor transparency and process perception metrics. | Review, Feedback Loop |
| **Transparency and Process Perception Metrics** | Capture perceptions of fairness, clarity, and visibility of how submissions were handled — through follow-up surveys, consultation feedback, and thematic analysis of complaints. | Feedback Loop, Review |
| **Reporting Framework and Output Templates** | Define standardised formats for *“What We’ve Heard”*, executive briefs, audit logs, and ICIP publication compliance. Supports consistent and traceable reporting practices. | Analysis, Publication |
| **MDBoK Library Card Enrichment** | Create structured metadata records (“Library Cards”) for selected submissions, quotes, or insights, enabling long-term discovery and reuse within MDBA’s Body of Knowledge. | Post-review, Archival |
| **Re-consent and Cultural Knowledge Reuse Trigger** | Manage situations where ICIP-tagged content may require updated consent or re-engagement for MDBoK reuse. | Archive, Knowledge Transfer |
| **Knowledge Metadata Mapping** | Align selected content with thematic or strategic classification for cross-program indexing and DAMF linkage. | Post-analysis, Knowledge Transfer |

**Figure 5: Capability Map – BPR Submissions Process**

This diagram illustrates the end-to-end capability model required to deliver and operate the Basin Plan Review submissions process. Capabilities are grouped into six Tier 1 domains — from stakeholder engagement through to information governance — with cross-cutting monitoring and reporting functions supporting transparency, performance tracking, and insight generation.

6. **Functional Requirements Summary**

This section defines the core functional capabilities required to support the end-to-end Basin Plan Review submissions process. These requirements translate the service concept and user journeys into tangible system behaviours — ensuring that submissions can be received, triaged, reviewed, and reported on in a way that is compliant, user-centred, and operationally feasible. Each function is directly tied to identified archetype needs, legal obligations, and blueprint scenarios, and will guide the implementation and configuration of the supporting platform.

| ID | Requirement | System Behaviour / Feature | Input/Trigger | Output / Dependency |
| :---- | :---- | :---- | :---- | :---- |
| **FR-01** | Multi-format Intake | Accept submissions via multiple intake channels including portal (short/detailed), kiosk (Riverside Chats), email, and physical mail. All formats normalised into a unified submission object. See Table 6\. for supported channels and formats. | File upload or manual entry | Normalised submission object |
| **FR-02** | Save and Return | Generate temporary submission ID and persist in-progress submissions; notify user via email with resume link. | Partial submission | Draft record; tokenised resume link |
| **FR-03** | ICIP Declaration and Handling | Submitters must be given the opportunity to declare if their submission contains Indigenous Cultural and Intellectual Property (ICIP). The declaration must be offered across all submission channels. If ICIP is declared, the system must flag the submission and initiate the ICIP review workflow. Where submissions are received via email or mail and ICIP is not explicitly declared, staff must assess indicators (keywords, content themes) and apply ICIP\_flag \= true only where clearly evident. Unclear cases default to ICIP\_flag \= false. | Submission intake via portal, kiosk, email, or physical mail | ICIP\_flag: true/false; audit trail entry; trigger to ICIP Review Coordinator (if true) |
| **FR-04** | Submitter Publication Preference | System must capture whether the submitter consents to being named in any published output. Consent must be explicit across all channels. For non-portal submissions (email, physical mail, kiosk), back-office staff must review and record consent status during upload based on submission content or provided declaration. If unclear or absent, system must default to anonymous publication (publication\_consent \= false). | Submission intake | publication\_consent=true/false metadata field |
| **FR-05** | Campaign Detection Engine | Detect pattern-matching submissions (e.g. via template similarity, email domains, volume spikes); flag as campaign-type. | Submission metadata \+ pattern DB | campaign\_tag=true |
| **FR-06** | Metadata Classification | Auto-tag submission with themes, region, format, campaign, sentiment (if applicable); support manual override. | Ingested submission | Metadata object attached |
| **FR-07** | RBAC | Enforce access rules per user group (e.g. Intake Officer, Legal, Analyst, Admin); log access events. | User login | Access token; access log |
| **FR-08** | Internal Submission Status Tracking | Track internal processing stage: intake, triaged, under\_review, withheld, published, archived. Used for workflow management, ageing, and reporting. | Workflow state change | review\_status metadata field; visible on internal dashboards only \+ Audit tracking |
| **FR-09** | Redaction Workflow | Route flagged submissions to Legal; redact inline or full submission; tag reason code (FOI, ICIP, Defamation). | Legal or ICIP trigger | Redacted submission; redaction reason |
| **FR-10** | SME Routing | Tag submission for SME; notify user group; allow markup/comments and decision recommendation. | Manual or metadata route | SME feedback object |
| **FR-11** | Insight Curation | Allow analysts to flag sections, quote text, and add tags for reporting; store link to source submission ID. | Analyst action | Quote repository \+ theme tag |
| **FR-12** | Report Generation Engine | Compile themed quotes, topics, campaign data, and flagged submissions into draft report (Markdown, Word, or HTML). | Report trigger | Exportable report |
| **FR-13** | Monitoring Dashboard | Display real-time graphs for volume, campaign activity, redaction load, tag distribution; backend polling every 5 min. | System activity | Dashboard UI \+ alert triggers |
| **FR-14** | Full Audit Logging | Record user actions per submission incl. view, redact, tag, comment, or publish; store immutable log. | User/system action | Time-stamped audit log |
| **FR-15** | Metadata Export \+ Records Integration | Export submission and metadata bundle to MDBA archive; apply retention rules and classification; generate export manifest. | Submission lifecycle end | Archive package \+ manifest |
| **FR-16** | Automated Notifications | The system must send automated email notifications to internal and external users for key actions such as submission receipt, status updates, and publication of submissions or reports | Submission events (e.g. submitted, reviewed, published) | Email alerts triggered to appropriate users |
| **FR-17** | Data Validation | The system must automatically validate data fields against predefined rules and flag errors or incomplete entries | Form completion and submission attempt | Validation error messages or acceptance confirmation |
| **FR-18** | Publication Management | Submissions designated as public must be published online in an accessible, searchable format. | Designation of submission as public | Public listing on portal |
| **FR-19** | Bulk Handling | Ability to bulk export, assign, or publish multiple submissions (e.g. handling identical campaign submissions efficiently). | Admin action on grouped submissions | Batch operation output; audit trail |
| **FR-20** | Publication Workflow | The system must support a controlled publication workflow including consent verification, redaction review, status assignment, bulk handling, approval tagging, and audit trail generation prior to publishing public submissions. The workflow must ensure compliance with publication rules and support transparent, traceable actions. | Submission approval or publication flag | Published submission; audit log; publication\_status=true |

**Table 15: Supported Submission Channels & Formats**

*Expanded detail from FR-01 to ensure shared understanding of all supported intake modes.*

| Channel | Mode | Supported Formats | Entry Point | Handled By | Tagged Metadata | System Notes |
| :---- | :---- | :---- | :---- | :---- | :---- | :---- |
| Portal – Short Form (Survey) | Self-service | Text fields, checkboxes | Public submission site | Public User | channel=portal-short | WCAG 2.1 AA accessible, consent mandatory |
| Portal – Detailed | Self-service | .pdf, .docx, .txt, .jpg, .mp4, .wav | Public submission site | Public User | channel=portal-detailed, ICIP\_flag | ICIP flag optional; submission template supported |
| Kiosk – Guided | Assisted (iPad) | Form entry, audio, scans | Riverside Chats | Staff Facilitator | channel=kiosk, entry\_by=staff | Staff-assisted; uploads through same portal entry point with 'kiosk' flag |
| Email | Manual ingest | Any attached format or email body text | Monitored inbox | Submission Manager | channel=email, submitter\_email | Uploaded by back-office user into system with channel=email and submitter email |
| Physical Mail | Scan and upload | Handwritten, typed, forms | Mailroom intake | Submission Team | channel=physical, entry\_by=staff | Tagged as physical; metadata entered by operator |

**Note:** These intake modes are functionally equivalent from a data perspective, but introduce different UX, metadata tagging, and support responsibilities. This table ensures all supported submission types are considered in implementation.

7. **Non-Functional Requirements Summary**

This section outlines the non-functional requirements (NFRs) that underpin the performance, security, maintainability, and integrity of the BPR Submissions Process platform. These requirements ensure that the service not only meets user and regulatory expectations, but remains resilient, ethical, and aligned with MDBA enterprise architecture principles.

| ID | Non-Functional Requirement | Description | Target / Standard |
| :---- | :---- | :---- | :---- |
| **NFR-01** | Availability and Uptime | System must remain available throughout the submission window, including peak hours and campaign surges. | ≥ 99.9% uptime during submission window |
| **NFR-02** | Scalability | Platform must scale to handle 10,000+ submissions, including bursts from high-volume campaigns. | Elastic or pre-provisioned autoscaling |
| **NFR-03** | Data Sovereignty | All submission data must be stored and processed within Australian jurisdiction. | Azure East or Southeast Australia only |
| **NFR-04** | Security and Access Control | Enforce SSO, MFA, and RBAC across all internal users; secure encrypted transport and audit logging. | Azure AD SSO; MFA; ISO27001-aligned |
| **NFR-05** | Accessibility | All public-facing interfaces must comply with WCAG 2.1 AA standards, including kiosk interface. | WCAG 2.1 AA certification |
| **NFR-06** | Auditability | System must maintain a tamper-proof, time-stamped audit trail of all actions on submissions. | Immutable audit logs with export functionality |
| **NFR-07** | Retention and Archiving | Submissions must be tagged with appropriate metadata and exported in accordance with MDBA’s DAMF retention and disposal rules. | DAMF-compliant export packages |
| **NFR-08** | System Monitoring | Provide real-time dashboards for system performance, error tracking, and workflow status. | Dashboard with alert thresholds |
| **NFR-09** | Maintainability | System configurations, workflows, and components should be modular, version-controlled, and easily maintainable. | Modular structure; Git-based versioning |
| **NFR-10** | Redaction and Data Obfuscation | Sensitive content (e.g. PII, ICIP) must be redacted or anonymised prior to public release and audit trail must reflect decisions. | Redaction module; defamation/FOI compliance |
| **NFR-11** | Disaster Recovery and Backup | Submissions and metadata must be backed up on a scheduled basis with tested recovery procedures. | Daily backups; restore in \<24 hours |
| **NFR-12** | Legal Hold Support | Ability to place selected submissions in a hold state where they are exempt from deletion or archiving, pending legal, ICIP, or FOI review. | Legal hold tagging capability |
| **NFR-13** | Interoperability | Submission data and metadata must be exportable in open or MDBA-aligned formats (e.g. JSON, CSV, XML) for downstream systems. | Structured export; schema mapping to DAMF |
| **NFR-14** | Anonymity Preservation | Submissions flagged as anonymous must be stripped of metadata or content that could indirectly re-identify the submitter. | Automated obfuscation checks; metadata scrub |
| **NFR-15** | Time Synchronisation | All timestamps in logs, submissions, workflows, and exports must be based on a common time source to ensure consistency. | ISO 8601 UTC standard; NTP-synchronised systems |
| **NFR-16** | Internal Status Visibility Only | The system must support internal tracking of submission status (e.g., triaged, under review, published) but does not surface submission-specific statuses to the public. Submitters receive a one-time confirmation only. | Internal dashboard only; no public tracking UI |

8. **Artefact & Template Recommendations**

Successful delivery and operation of the Basin Plan Review submissions process will depend not only on system functionality, but on the clarity, consistency, and accessibility of supporting artefacts and templates. These artefacts ensure a shared understanding of the process, support legal and cultural compliance, and enable MDBA teams and submitters to interact confidently and correctly at each stage.

Artefacts should be version-controlled, formally endorsed, and available through the BPR content management system or staff portal.

| Artefact / Template | Purpose / Use Case | Owner / Maintainer |
| :---- | :---- | :---- |
| **Submission Guidelines** | Public-facing document outlining how to make a submission, what is in/out of scope, and consent instructions. | CM\&E / Legal |
| **ICIP Declaration Statement (template)** | Embedded text for submission forms/email/mail instructing users how to declare ICIP content. | Legal / Indigenous Engagement |
| **Consent to Identification Clause** | Reusable clause for forms and guidance documents, enabling submitters to opt-in or out of name disclosure. | Legal |
| **Email and Mail Submission Coversheet** | Printable coversheet with consent and ICIP checkboxes for physical and email-based submission workflows. | Submission Manager |
| **Triage and Routing Matrix** | Internal matrix used to assess, tag, and route submissions to appropriate reviewers or workflows. | BPR / Analysts |
| **Redaction and Legal Review Ruleset** | Internal workflow and criteria for defamation, FOI, and ICIP redaction. | Legal / Compliance Custodian |
| ***“What We’ve Heard”* Report Template** | Structured template for public reporting, including quote use, metadata, and thematic headings. | Strategic Synthesiser / Comms |
| **Submission Metadata Dictionary** | Defines the standard metadata tags applied to submissions (e.g., topic, location, ICIP flag). | Platform Guardian / Records Officer |
| **Records Retention and Export Guide** | Instructions for archiving, exporting, and classifying submissions in line with DAMF. | Records Management |
| **Submission Processing Checklist** | Internal checklist for each submission journey — from intake to publication. | Process Steward |
| **Staff Script – Kiosk Support** | Script for staff assisting at Riverside Chats to ensure consent and ICIP prompts are consistently delivered. | CM\&E / Legal |
| **Submission Entry Form Template (mail/email)** | Simple editable version of the portal form for non-digital submissions. | CM\&E |

**Appendix A**  
Persona-Archetype Mapping

| Archetype | Included Personas | Shared Characteristics |
| :---- | :---- | :---- |
| **Engaged Contributor** | Community Member Environmental Advocate First Nations Submitter Water Broker / Trader Industry Representative Local Council Officer | Motivated to participate in the Basin Plan Review process. May act individually or on behalf of a group. Requires fair, respectful, and accessible options to submit views. |
| **Process Steward** | BPR Coordination Team Submissions Administrator Mailroom Staff Project Manager | Responsible for coordinating intake, managing submission workflows, ensuring traceability, and maintaining compliance across operational processes. |
| **Platform Guardian** | ICT System Administrator Application Support Officer Records Management Lead | Ensures systems are stable, secure, accessible, and compliant with MDBA's digital architecture. Manages uptime, integration, and monitoring infrastructure. |
| **Compliance Custodian** | Legal Advisor Privacy Officer ICIP Review Coordinator | Oversees adherence to legal, cultural, and privacy obligations including ICIP, FOI, and consent. Manages redaction and sensitive publication workflows. |
| **Strategic Synthesiser** | Analyst Program Evaluator Communications and Engagement Lead MDBA Policy Officer | Responsible for analysing submissions, drawing out themes and insights, and producing strategic and public-facing reports. Requires powerful filtering and synthesis tools. |

**Note:** This mapping represents a consolidation of user roles and perspectives based on available discovery inputs, but does not include a distinct persona artefact for every stakeholder type listed. Some personas were inferred through consultation or role description rather than developed as standalone profiles. Additionally, there may be other users or edge cases not captured within this framework. This mapping should be treated as indicative, not exhaustive, and refined as further engagement occurs.

**Appendix B**  
Alignment to Water Act 2007 s51 obligations

Section 51 of the Water Act 2007 (Cth) outlines the legislative requirements for the Authority to publish draft and final versions of the Basin Plan, consult with the public and relevant bodies, and consider feedback in finalising the Plan. This appendix maps these obligations to corresponding elements of the BPR Submissions Process Service Concept.

| s51 Obligation | Design Response | Supporting Features / Artefacts |
| :---- | :---- | :---- |
| **(1)(a)** *Give the public an opportunity to make submissions on the proposed Basin Plan.* | Multi-format intake channels (portal, email, mail, guided kiosk) ensure wide accessibility and inclusion across communities. | Submission portal, kiosk form, Submission Guidelines, Artefact F: Channel Matrix |
| **(1)(b)** *Have regard to any submissions made by the public.* | Workflow ensures each submission is triaged, tagged, and routed to reviewers. Public submissions are captured for thematic analysis. | Metadata tagging, Analyst workflows, *“What We’ve Heard”* reporting engine |
| **(1)(c)** *Give each relevant Basin State an opportunity to make submissions.* | Recognised stakeholder category in submission guidance and metadata tagging. State submissions routed for strategic synthesis. | Persona mapping, triage logic, stakeholder tagging in metadata |
| **(1)(d)** *Have regard to those submissions from Basin States.* | Dedicated review step ensures Basin State submissions are logged, synthesised, and formally recorded as considered. | SME routing, reporting capture, audit logging |
| **(2)** *Manner of consultation must be appropriate and reflect principles of community engagement.* | Designed around accessibility, inclusion, and culturally safe participation. Supports WCAG AA, ICIP protocols, and FPIC standards. | Accessibility compliance, ICIP workflow, cultural governance input, Artefact library |
| **(3)** *Authority must publish the final Basin Plan with an explanation of how issues raised were addressed.* | *“What We’ve Heard”* reports provide transparency, mapping raised issues to response themes and actions. | Reporting framework, Insight tagging, Publication workflows, Artefact: WWH Report Template |

**Note:** The service concept embeds these obligations through design principles such as *Compliance by Design*, *Transparent Consideration*, and *Ethical and Respectful Engagement*. Ongoing validation with Legal and Compliance Custodians will ensure fidelity to legislative interpretation.

**Appendix C**  
Compliance Checkpoints and Controls

The Basin Plan Review Submissions Process must comply with multiple legislative and ethical frameworks, including the *Water Act 2007*, *Privacy Act 1988*, *Freedom of Information Act 1982*, and ICIP principles. This appendix outlines where compliance controls are embedded within the service journey, who is accountable, and what mechanisms support assurance.

| Compliance Area | Checkpoint | Service Phase | Control Mechanism | Responsible Role |
| :---- | :---- | :---- | :---- | :---- |
| **Water Act 2007 – s51** | Public and State submission handling | Intake, Analysis | Open channels, metadata tagging, SME routing | Process Steward / Legal Advisor |
| **Privacy – Publication Consent** | Submitter chooses to be named or remain anonymous | Intake | Mandatory consent field on all channels (FR-15); default \= anonymous if unclear | Process Steward / Legal Advisor |
| **Privacy – Data Handling** | Secure storage and audit of submission content | All phases | Onshore hosting, audit logs, RBAC, immutable logging (NFR-03, NFR-06) | Platform Guardian |
| **ICIP Declaration and Review** | Submissions containing cultural knowledge flagged | Intake, Review | Optional ICIP field; ICIP Review Coordinator approval required before publication | ICIP Coordinator / Legal |
| **FOI / Legal Risk** | Redaction of defamatory or sensitive content | Review, Publication | Legal review workflow; redaction tool; reason tagging | Legal Advisor |
| **Accessibility (WCAG 2.1 AA)** | Interface accessibility compliance | Portal, Kiosk | Form validation, contrast checks, screen reader support | Platform Guardian |
| **Records Management (DAMF)** | Retention, export, and archival of submission data | Publication, Archive | Metadata schema, export manifest, archive routine | Records Officer |
| **Ethical Engagement / FPIC** | Respectful interaction with First Nations communities | Guidance, Submission | ICIP declaration, staff scripts, co-design review | Indigenous Engagement / CM\\\&E |
| **Governance & Oversight** | Escalation and oversight pathways | All phases | Operating Model swimlanes; ARG involvement; CI cadence | Governance Group |

**Note:** Controls have been embedded as functional requirements (Section 6), design principles and elements (Section 3.6 & 3.7), and process roles (Section 4). Compliance checkpoints should be periodically reviewed and validated through internal audit or review mechanisms.

**Appendix D**  
Data & Privacy Flow Map

This appendix describes the flow of submission data from intake to archival, highlighting key privacy protection points, consent triggers, and data classification activities. The flow aligns with the requirements of the *Privacy Act 1988*, MDBA’s **Data and Metadata Framework (DAMF)**, and relevant obligations under the **Water Act 2007, FOI**, and **ICIP governance principles**.

## **D.1 Overview Flow Description** {#d.1-overview-flow-description}

Submission data passes through six primary stages, each with distinct privacy obligations and technical controls:

1. **Submission Intake**  
   * Data is received via portal, kiosk, email, or physical mail.  
   * Consent for identification and ICIP is captured (explicit for digital channels, inferred or staff-logged for manual channels).  
   * Metadata applied at entry: source, timestamp, ICIP flag, publication consent, etc.  
2. **Validation & Triage**  
   * Submissions are tagged (e.g. campaign, anonymous, ICIP).  
   * Basic redactions may occur at this stage if sensitive content is flagged.  
   * Non-compliant submissions are quarantined.  
3. **Review & Analysis**  
   * Content analysed by authorised internal users (e.g. Analysts, Legal).  
   * Further metadata added (themes, issues, tone).  
   * ICIP and legal review workflows triggered where relevant.  
4. **Publication Preparation**  
   * Only content with consent is attributed by name.  
   * Redactions (e.g. PII, defamation, ICIP) applied before export.  
   * Content passed into *“What We’ve Heard”* or analytical outputs.  
5. **Export & Reporting**  
   * Data exported into Power BI dashboards and structured reports.  
   * Submitter identities included only where authorised.  
   * Report metadata includes tags for audit and FOI traceability.  
6. **Retention & Archival**  
   * Final data packages stored with retention flags per DAMF.  
   * Legal holds and ICIP safeguards override normal archival flow.  
   * Export formats compatible with FOI and future public release.

## **D.2 Privacy Safeguards by Stage** {#d.2-privacy-safeguards-by-stage}

| Stage | Key Safeguards |
| :---- | :---- |
| **Intake** | Explicit consent capture (ID/ICIP); staff scripts; WCAG-compliant forms; metadata tagging |
| **Triage** | System quarantine rules; tagging engine; secure S3/Blob storage; input validation |
| **Review** | Role-based access; audit trail; ICIP & legal approval workflows |
| **Publication** | Redaction module; defamation/ICIP checks; quote authorisation filters |
| **Export** | Filtered datasets; de-identified exports where required |
| **Archive** | DAMF-aligned classification; legal hold mechanism; long-term retrieval support |

## **D.3 Flow Map** {#d.3-flow-map}

|  |  |
| :---- | :---- |

**Note:** The above diagrams illustrate how submission data flows through intake, triage, review, publication, and archiving — with key privacy protections and legal controls embedded throughout.

**Appendix E:**  
Objectives Mapping

This appendix maps the intended objectives of the submissions process to their corresponding design mechanisms within the Service Concept. It ensures traceability between strategic intent, service features, and delivery outcomes. Objectives are drawn from the Discovery Brief, MDBA’s Corporate Plan and Digital Strategy, and Section 51 of the *Water Act 2007*.

| Objective | Design Alignment | Service Mechanisms |
| :---- | :---- | :---- |
| **Enable meaningful participation by all stakeholders** | Multi-channel intake, guided kiosk, short/detailed form pathways, culturally respectful language and tone | Submission portal, kiosk UX, First Nations guidance, consent workflows |
| **Meet legal and policy obligations under the Water Act 2007 s51** | Service structure aligned to s51: submission opportunity, state engagement, public transparency | Functional blueprints, compliance checkpoints, reporting workflows |
| **Support ethical and culturally safe engagement, especially with First Nations contributors** | ICIP declaration, redaction protocols, Indigenous-led governance input | ICIP workflow, staff scripts, submission guidance artefacts |
| **Ensure data is handled securely, transparently, and in compliance with MDBA governance** | DAMF alignment, metadata tagging, redaction logic, onshore data storage | Metadata standards, system logging, Records Officer role, Azure compliance |
| **Promote transparency in how submissions influence the review** | What We’ve Heard reporting model, quote tagging, feedback loop for contributors | Public reporting template, synthesis tagging, anonymous publication consent |
| **Support efficient internal operations and traceable processing** | Submission tracking, workflow routing, internal dashboarding | Process steward blueprint, role-based access, triage rules, analytics views |
| **Deliver a service that is operationally lightweight but repeatable for future Basin Plan cycles** | Modular design, documented artefacts, exportable models and forms | Artefact library, scalable platform components, capability map with future adaptation points |

**Appendix F**  
Service Products

This attachment outlines the core service products required to operationalise the Basin Plan Review submissions process. These products enable users to engage effectively, support internal workflows, and ensure compliance with legislative and ethical obligations. Some products are user-facing (external), while others support internal teams in managing, triaging, and reporting on submissions.

The service products listed here are aligned with the customer journeys, design principles, and system requirements described in the main Service Concept document. They span the full lifecycle of the submissions process — from public invitation to archival — and will form the foundation for implementation, co-design, and system development activities.

**Note:** List may change as service design is refined and moves from this concept into a more detailed stage.

## **Submission Guidance & Consent** {#submission-guidance-&-consent}

| ID | Service Product | Description | Service Phase | InternalExternal |
| ----- | ----- | ----- | ----- | ----- |
| SP01 | Submission Guidelines | Plain-language submission guide covering scope, process, privacy, ICIP, and consent. | Invitation, Collection | External |
| SP02 | Scope/out-of-Scope Examples Sheet | Quick-reference summary of what the Authority can and cannot consider under Section 51\. | Invitation | External |
| SP03 | ICIP Consent Form | Two-page form defining time-bound, revocable, purpose-specific consent for ICIP content. | Collection | External |
| SP04 | Consent and Privacy Policy Page | Portal-based explanation of privacy rights, consent options, and retraction procedures. | Collection | External |
| SP05 | Redaction Guidance | Explainer for contributors on how sensitive content is managed, redacted, or excluded from reports. | Collection | External |

## **Submission Intake & Interface** {#submission-intake-&-interface}

| ID | Service Product | Description | Service Phase | Internal/External |
| ----- | ----- | ----- | ----- | ----- |
| SP06 | Submission Portal | Digital platform to upload and lodge submissions in multiple formats with consent tagging. | Collection | External |
| SP07 | Save & Return Draft Functionality | Enables users to return to partially completed submissions. | Collection | External |
| SP08 | Assisted Submission Channel SOP | Standard operating procedure for in-person, oral, or facilitated submissions (e.g. Riverside Chats). | Collection | Internal |
| SP09 | Accessibility Compliance Checklist | Checklist to ensure digital and offline products meet WCAG AA requirements. | Invitation, Collection | Internal |
| SP10 | Metadata Tagging Schema | Controlled vocabulary and tagging model for issues, topics, ICIP, sentiment, and archetype. | Collection, Analysis | Internal |

## **Processing, Triage & Workflow** {#processing,-triage-&-workflow}

| ID | Service Product | Description | Service Phase | InternalExternal |
| ----- | ----- | ----- | ----- | ----- |
| SP11 | Triage Matrix & Escalation Ruleset | Decision logic for flagging submissions for legal, ICIP, or defamation review. | Collection, Analysis | Internal |
| SP12 | Campaign Grouping Engine | Rules and tooling for deduplicating mass-submission campaigns. | Analysis | Internal |
| SP13 | Submission Processing Tracker | Dashboard to monitor submission counts, routing, and processing progress. | Analysis, Consideration | Internal |
| SP14 | SME Review Assignment Workflow | Role-based workflow for allocating submissions to reviewers by topic or risk level. | Consideration | Internal |
| SP15 | Redaction SOP | Standardised process for handling personal, ICIP, or defamatory information. | Analysis, Publication | Internal |
| SP16 | Cultural Metadata Flags | ICIP-aware labels to identify sensitive cultural or community-owned knowledge. | Collection, Analysis | Internal |
| SP17 | Legal Escalation Protocol | Steps for referring flagged submissions to legal counsel. | Consideration | Internal |

## **Reporting & Feedback** {#reporting-&-feedback}

| ID | Service Product | Description | Service Phase | Internal/External |
| ----- | ----- | ----- | ----- | ----- |
| SP18 | *“What We’ve Heard”* Report Template | Structured summary of submission themes, quotes, and insights. | Reporting | External |
| SP19 | Executive Insight Briefing Pack | Pre-formatted reporting for ELT and BPR Steering Committee. | Reporting | Internal |
| SP20 | Public Dashboard (Aggregated) | Public-facing visualisation of volume and themes across submissions. | Feedback | External |
| SP21 | Influence Log Tool | Tracks which submission themes influenced policy or reporting outcomes. | Feedback, Audit | Internal |
| SP22 | Status Notification Engine | Automated email engine for submission receipt, status, and publication updates. | Collection, Feedback | External |

## **Records, Archive & Governance** {#records,-archive-&-governance}

| ID | Service Product | Description | Service Phase | InternalExternal |
| ----- | ----- | ----- | ----- | ----- |
| SP23 | Submission Archive with Legal View | Secure, auditable repository with versioning, metadata, and consent history. | Records Management | Internal |
| SP24 | FoI and PIA Compliance Log | Record of submission exemptions, redactions, and risk assessments. | Records, Legal | Internal |
| SP25 | Lessons Learned Register | Repository for process improvements, system gaps, and post-review evaluations. | Cross-phase | Internal |
| SP26 | Submission ID Registry | Unique ID schema to enable cross-platform traceability of each submission. | All Phases | Internal |
| SP27 | Campaign Response Toolkit | Set of comms and procedural tools for managing high-volume campaign submissions. | Collection, Analysis | Internal |

## **Co-design & Engagement Tools** {#co-design-&-engagement-tools}

| ID | Service Product | Description | Service Phase | InternalExternal |
| :---- | :---- | :---- | :---- | :---- |
| SP28 | User Testing Protocol | Framework for co-design sessions with real users (e.g. First Nations contributors, State officials). | Design, Validation | Internal |
| SP29 | Submission Guide – First Nations | A culturally appropriate variant of the submission guide with “on Country” context and language. | Invitation, Collection | External |
| SP30 | Community Pack for Facilitators | Printable guides, posters, and templates for on-the-ground engagement staff (e.g. at stalls/events). | Invitation | Internal |

## **Ethics, Risk & ICIP Governance** {#ethics,-risk-&-icip-governance}

| ID | Service Product | Description | Service Phase | Internal/External |
| :---- | :---- | :---- | :---- | :---- |
| SP31 | ICIP Tagging Guide | Detailed internal guide for recognising, tagging, and handling ICIP in all submission formats. | Collection, Analysis | Internal |
| SP32 | ICIP Reuse Request Form | Formal process to request permission to re-use ICIP beyond original consent terms. | Feedback, Reuse | Internal |
| SP33 | Ethical Review Checklist | Quick-reference checklist to ensure ethical treatment of data, cultural content, and consent. | Collection, Publication | Internal |

## **Implementation & Handover Tools** {#implementation-&-handover-tools}

| ID | Service Product | Description | Service Phase | Internal/External |
| :---- | :---- | :---- | :---- | :---- |
| SP34 | operating Model Handbook | Summarises governance roles, escalation paths, and lifecycle ownership. | Cross-phase | Internal |
| SP35 | RACI Matrix for Submission Workflow | Maps responsibilities across teams for each part of the submission lifecycle. | Cross-phase | Internal |
| SP36 | Implementation Tracker | Tool to monitor development, piloting, and release of each product or service component. | Planning, Delivery | Internal |

**Appendix G**  
Submission Channels Table

| Channel | Description | Consent to Identification | ICIP Declaration | Responsible Role |
| :---- | :---- | :---- | :---- | :---- |
| **Portal(Short – Survey)** | Web-based structured form with predefined questions for quick and easy input. | Required checkbox or radio selection (must choose) | Optional checkbox with guidance tooltip | Platform Guardian / CM\&E |
| **Portal(Long – Detailed)** | Web-based form supporting detailed submissions with attachments (documents, audio, video, etc.). | Required checkbox or radio selection (must choose) | Optional checkbox with guidance tooltip | Platform Guardian / CM\&E |
| **Guided Kiosk (Riverside Chats)** | Staff-assisted entry using an MDBA iPad running the Portal in a controlled or kiosk mode. May collect different or richer metadata via a distinct kiosk workflow. | Staff reads prompt and selects answer on user’s behalf | Staff reads prompt and records ICIP response | Process Steward / CM\&E |
| **Email Submission** | Submissions received via monitored inbox (attachments or inline text). | Submitters instructed to declare; if unclear, default \= false | Submitters instructed to declare; staff must assess | Submission Manager |
| **Physical Mail** | Posted submissions, optionally using a coversheet template to capture metadata. | Coversheet includes consent checkbox; if missing, default \= false | Coversheet includes ICIP checkbox; fallback is content review | Mailroom / Submission Admin |

**Note:** In all cases, if consent to be identified or ICIP status is not clearly stated, system and staff must default to protective handling: publication\_consent \= false, ICIP\_flag \= false, and submission routed for review if flagged.

**Appendix H**  
Submission Data Object Model

This appendix outlines the standardised data object used to represent each submission, regardless of intake channel or format. The model supports structured handling, compliance with the *Privacy Act 1988*, FOI and ICIP obligations, and MDBA’s DAMF-aligned information governance requirements.

| Field Name | Type | Description | Example / Format | Mandatory? |
| :---- | :---- | :---- | :---- | :---: |
| submission\_id | UUID | System-generated unique identifier for each submission. | 550e8400-e29b-41d4-a716-... | ✅ |
| submitter\_name | String | Submitters name (only stored if publication consent is given). | “Jane Smith” | ⛔(conditional) |
| submitter\_email | String (email) | Email used for receipt/communication (if available). | example@email.com | ⛔ |
| channel | Enum | Source of submission: portal-short, portal-detailed, email, mail, kiosk, etc. | “portal-detailed” | ✅ |
| date\_received | DateTime | Timestamp when the submission was formally logged in the system. | 2025-07-01T13:42:00Z | ✅ |
| publication\_consent | Boolean | Whether the submitter consents to being named in public-facing materials. | true / false | ✅ |
| ICIP\_flag | Boolean | Indicates whether submission contains Indigenous Cultural and Intellectual Property. | true / false | ✅ |
| ICIP\_review\_status | Enum | Workflow status of ICIP review (pending, approved, withheld) | “pending” | ⛔(if flagged) |
| redaction\_required | Boolean | Flag for legal or privacy-based redaction requirement. | true / false | ⛔ |
| redaction\_notes | String | Free-text notes from Legal or Compliance team explaining redaction. | “Defamatory reference removed” | ⛔ |
| submission\_text | Text | Raw or extracted text from the submission. | (long form) | ✅ |
| attachments | List\\\[File\] | Files attached to the submission (PDFs, photos, videos). | \[file1.pdf, photo2.jpg\] | ⛔ |
| metadata\_tags | List\\\[String\] | Thematic or regional tags assigned manually or automatically. | \["environment", "NSW", "flows"\] | ⛔ |
| quote\_flag | Boolean | Indicates whether content has been flagged for potential quoting in public reports. | true / false | ⛔ |
| review\_status | Enum | Workflow state: intake, triaged, under\_review, published, archived | “under\_review” | ✅ |
| submitted\_by\_staff | Boolean | Indicates whether submission was entered on behalf of the submitter (e.g. kiosk or mailroom). | true / false | ✅ |
| assigned\_to | String (user ID) | Staff user currently responsible for review or triage. | user\_324a7f | ⛔ |
| audit\_log\_reference | UUID | Link to immutable audit record of interactions and changes. | a1b2c3d4-e5f6-... | ✅ |
| retention\_class | Enum | Retention classification aligned with DAMF (e.g. long-term, FOI-sensitive, disposable) | “long-term” | ✅ |

**Disclaimer:**

This model is intended as a **logical reference only**. It reflects insights gathered during the discovery and design phases and is provided to support high-level alignment across governance, digital, and operational domains.

The data structure shown in this appendix is **not a** **formal schema specification**.

Any future implementation must be preceded by detailed business analysis, information governance review, and solution architecture planning. Field names, formats, and workflows are subject to refinement based on technical constraints, platform selection, and legal or privacy requirements at the time of build.

**Appendix I**  
Workflow Register

This appendix documents the core workflows underpinning the service concept. Each workflow describes a repeatable operational process that enables secure, compliant, and efficient handling of submissions throughout their lifecycle. These workflows are conceptual in nature and must be further validated and refined during detailed process design, business analysis, and system implementation.

**Note:** This register supports traceability to functional requirements (Section 6), service blueprints (Section 3), and the operating model (Section 4).

| Workflow Name | Purpose | Trigger | Key Roles Involved | Outcome / Value | System Dependencies |
| ----- | ----- | ----- | ----- | ----- | ----- |
| **1\. Submission Intake** | Convert received submission into a standardised object with metadata | Submission via any channel | Submitter, Kiosk Staff, Submission Admin | Submission created; metadata captured; consent stored | Submission portal, intake API, file parser, metadata tagging engine, channel detection logic |
| **2\. Triage and Routing** | Assign submission for review based on content, tags, or risk flags | New submission logged | Process Steward, SME, Legal, ICIP Review Coordinator | Submission routed to correct workflow; status updated | Workflow engine, auto-tagging module, campaign detection logic, dashboard, reviewer assignment tool |
| **3\. ICIP Review** | Ensure cultural safety of submissions containing Indigenous knowledge | ICIP flag triggered | ICIP Review Coordinator, Legal, Indigenous Advisors | ICIP status resolved; publication restrictions applied | ICIP flag, review dashboard, consent metadata viewer, legal/ICIP comment interface |
| **4\. Legal / Redaction Review** | Identify and redact sensitive, defamatory, or FOI-exempt content | Redaction flag, Legal escalation | Legal Advisor, Compliance Custodian | Redacted submission; legal risk managed | Redaction interface, FOI flagging system, audit trail logger, publication eligibility checker |
| **5\. Publication Consent Check** | Determine if submitter can be named in public outputs | Prior to quoting or publication | Process Steward, Legal Advisor | Identity either shown or withheld in public materials | Consent flag in metadata, quote approval tool, public view generator |
| **6\. SME Review and Comment** | Enable subject matter experts to annotate and assess submissions | Routed by triage | SME Reviewer, Analyst | Submission reviewed, tagged, commented, or escalated | Reviewer dashboard, tagging UI, comment thread module, history tracker |
| **7\. Quote & Insight Curation** | Select representative quotes and insights for WWH reporting | During analysis phase | Strategic Synthesiser, Comms Lead | Quotes linked to metadata; public outputs drafted | Quote tagging engine, quote repository, WWH export formatter, publication status checker |
| **8\. Submission Status Tracking** | Track the internal status of submissions for triage, legal review, redaction, and publication. Used for backlog visibility, escalation, and internal reporting. | Status change event | Process Steward, Legal Advisor, ICIP Coordinator | Supports timely workflow management, ageing analysis, and compliance assurance. | Internal status tracker, dashboard UI, audit logger, ageing logic |
| **9\. Reporting and Export** | Generate datasets and outputs for reporting, insight, and publication | WWH reporting or executive request | Analyst, Strategic Synthesiser, ICT | WWH reports, Power BI datasets, quote export | Analytics layer (Power BI), export service (CSV, JSON), publication approval flow |
| **10\. Retention & Archival** | Classify, tag, and export submissions for compliant long-term storage | Submission lifecycle complete | Records Officer, ICT Operations | DAMF-compliant archival package; retention triggered | Metadata classification tool, DAMF retention engine, export manifest generator, archive storage moduleDESTRUCTION |
| **11\. MDBoK Library Card Enrichment** | To curate and tag selected submissions or insights for long-term inclusion in the MDBoK knowledge system. | Flagged during insight curation, post-review, or by ICIP/Records team as culturally, historically, or strategically valuable. | Strategic Synthesiser, Records Officer, Indigenous Knowledge Advisor, Knowledge Management (MDBoK lead) | Ensures submissions or excerpts are captured as long-term knowledge artefacts, appropriately governed and retrievable. | Insight tagging interface; Library Card metadata schema; DAMF alignment; Re-consent triggers (if ICIP); Link to submission UUID and quote repository |

**Appendix J**  
Service Concept Background

## **The purpose of the service concept** {#the-purpose-of-the-service-concept}

The Service Concept provides a structured vision for how the Basin Plan Review submissions process will work in practice — from the perspective of users, staff, and systems. It acts as a foundational artefact that bridges stakeholder needs, legislative requirements, and digital implementation.

It describes the intended service experience, clarifies process logic and roles, and identifies the capabilities required to deliver a compliant, respectful, and efficient consultation process. The concept is not a solution blueprint or technical specification — rather, it sets out the “*what*” and “*why*” of the service so that the “*how*” can be developed in alignment with user needs, legal obligations, and MDBA's digital strategy.

It is used to:

* Guide co-design and validate shared understanding across stakeholders

* Align service delivery with strategic, legal, and ethical objectives

* Enable structured analysis of roles, risks, data, and decision points

* Inform future implementation, procurement, and review activities

**Note:** This document forms part of Phase 3 of the design process and should be read in conjunction with supporting materials, including the Discovery Brief, service blueprints, and capability model.

**Appendix K**  
Strategic Crosswalk

This appendix demonstrates how the service concept aligns with the MDBA Values, Digital Strategy 2023–25 and the service principles, ensuring delivery is consistent with MDBA’s enterprise-wide digital priorities and ICT governance.

## **MDBA Digital Strategy Pillars** {#mdba-digital-strategy-pillars}

* Pillar 1 \- Digital Workplace and Service Accessibility

* Pillar 2 \- Information Management and Governance

* Pillar 3 \- ICT Operations and Resilience

* Pillar 4 \- Data Ethics, Privacy, and Risk

### **Table K.1 – Design Principles vs MDBA Digital Strategy** {#table-k.1-–-design-principles-vs-mdba-digital-strategy}

| Design Principle | Description | Digital Strategy Pillar Alignment |
| :---- | :---- | :---- |
| **Compliance by Design** | Embed legislative, records, ICIP, and privacy obligations from the start, not as a retrofit. | Pillar 2, Pillar 4 |
| **User-Centred Inclusion** | Ensure inclusive, intuitive, and accessible services for all contributors and internal users. | Pillar 1, Pillar 4 |
| **Configure Before Code** | Prioritise proven platform configuration over bespoke development, aligned with EA guidance. | Pillar 1, Pillar 3 |
| **Scalable and Flexible** | Support large-scale, multi-format submissions with adaptable workflows. | Pillar 1, Pillar 3 |
| **Data Stewardship & Sovereignty** | Ensure ethical, onshore data storage with lifecycle governance aligned to DAMF. | Pillar 2, Pillar 4 |
| **Transparent Consideration** | Show how submissions are handled, considered, and influence outcomes. | Pillar 1, Pillar 4 |
| **Ethical and Respectful Engagement** | Honour cultural protocols and support informed consent, especially for First Nations contributors. | Pillar 4 |

### **Table K.2 – Key Service Features vs MDBA Digital Strategy Pillars** {#table-k.2-–-key-service-features-vs-mdba-digital-strategy-pillars}

| Service Feature or Capability | Description | Strategic Pillar Alignment |
| :---- | :---- | :---- |
| **Metadata tagging and triage routing** | Structured tagging supports filtering, escalation, and defensibility. | Pillar 2 |
| **Consent and ICIP flagging engine** | Consent metadata and cultural protection labels guide publication decisions. | Pillar 4 |
| **Submission portal with save-and-return** | Improves user experience and supports draft submissions over time. | Pillar 1 |
| **Redaction workflow with legal escalation** | Ensures sensitive data is managed compliantly and FOI-ready. | Pillar 2, Pillar 4 |
| **Real-time dashboard and campaign detection** | Enables monitoring of volume spikes and systemic stress points. | Pillar 3 |
| ***“What We’ve Heard”* publishing engine** | Supports transparent public reporting on submissions and themes. | Pillar 1, Pillar 4 |
| **Records and retention tagging** | Automates storage classification and lifecycle alignment with DAMF. | Pillar 2 |
| **Role-based access for internal users** | Supports secure, auditable user access aligned with business responsibilities. | Pillar 1, Pillar 3 |
| **Post-submission analytics and insight dashboard** | Extracts structured knowledge from submissions to inform review and reporting. | Pillar 1, Pillar 2 |
| **FOI and ICIP compliance checkpoints** | Embedded through workflow stages to avoid retroactive remediation. | Pillar 2, Pillar 4 |

### 

### **Table K.2 – Expanded Objectives Alignment** {#table-k.2-–-expanded-objectives-alignment}

| MDBA Values | Strategic Objectives & Domains | ICT Strategy Domains | Design Principles | Design Elements |
| :---- | :---- | :---- | :---- | :---- |
| **Being in Community** | Empowered Contributors | Digital Workplace | User-Centred Inclusion | Kiosk channels, simple forms |
|  | Trusted Process | Records Governance | Compliance by Design | Consent handling, redaction |
|  | Knowledge Retention | Lifecycle Retention | Data Stewardship | Metadata tagging, DAMF flags, MDBoK enrichment |
|  | Insight Quality | Open Data Readiness | Transparent Consideration | Feedback loop visibility |
|  | Compliance | Security & Compliance | Ethical Engagement | ICIP guidance, CARE/FAIR alignment |
|  | Efficiency | Service Scalability | Configure Before Code | Workflow modularity |
|  | Engagement | Stakeholder Interaction | User-Centred Inclusion | Multi-format submission |
|  | Transparency | FOI Readiness | Transparent Consideration | Submission tagging & dashboards |
| **Being Courageous** | Compliance | Records Governance | Compliance by Design | Redaction workflow |
|  | Insight Quality | Insight Systems | Transparent Consideration | Quote extraction tools |
|  | Ethical Service | Auditability | Ethical Engagement | Audit trails |
|  | Cultural Integrity | ICIP Handling | Ethical Engagement | ICIP workflows |
|  | Operational Ownership | BAU Maturity | Configure Before Code | BAU ownership artefacts |
|  | Accountability | Escalation Clarity | Compliance by Design | Governance triggers |
| **Bringing Energy** | Efficiency | Automation | Scalable & Flexible | Bulk handling of campaign content, triage logic |
|  | Insight Quality | Analytics | Data Stewardship | Thematic clustering |
|  | Platform Stability | System Interoperability | Configure Before Code | Power Platform integrations |
|  | Innovation | UX Methods | Scalable & Flexible | Analytics dashboard |
|  | Data Governance | Metadata Framework | Data Stewardship | Retention rules & export |

**Appendix L**  
Previous Work and Resources

This Service Concept builds on a significant body of work completed during earlier phases of the Basin Plan Review Submissions Process project, as well as relevant enterprise frameworks, legal instruments, and deep dive engagements. This appendix lists the key documents, artefacts, and inputs that informed the design decisions presented in this document.

| Title | Description / Use in Service Concept | Source / Owner |
| :---- | :---- | :---- |
| **MDBA\\\_BPR Process Design – Discovery Brief (v0.2)** | Summarised findings from Phase 2 discovery, including insights, personas, and early service structure | Atturra / BPR Design Team |
| **User Persona Posters** | Early user research and persona development that informed archetype consolidation | Atturra / CM\&E |
| **Service Concept – Better Practice Example** | Referenced as structural model for defining the service concept and design artefacts | DTA / External Reference |
| **Water Act 2007 – Section 51** | Legislative obligations that underpin submissions process requirements | Federal Register / Legal Advisor |
| **MDBA Digital Strategy 2023–2025** | Strategic alignment to MDBA’s digital goals, platforms, and compliance expectations | MDBA ICT & Strategy Division |
| **MDBA DAMF – Data & Metadata Framework** | Used to guide metadata tagging, retention policy, and archiving logic | MDBA Records & Governance |
| **Enterprise Architecture Framework (2022)** | Ensures solution is consistent with MDBA’s architecture, cloud, and technology standards | MDBA ICT / Architecture Team |
| **ICIP Deep Dive Replay (April 2025\)** | Informed culturally safe submission handling and ICIP review requirements | Atturra / Legal / Indigenous Advisors |
| **ICT Deep Dive Replay (April 2025\)** | Identified integration constraints, RBAC logic, system uptime, and governance requirements | Atturra / MDBA ICT |
| **CM\\\&E Deep Dive Replay (April 2025\)** | Supported design of outreach, kiosk interaction, and inclusive submission guidance | Atturra / CM\&E |
| **Legal and Governance Deep Dive Replay (April 2025\)** | Defined redaction criteria, legal risk handling, and consent model | Atturra / Legal Advisor |
| **OECD – Guidelines for Citizen Participation Processes (September 2022\)** | Provided reference for inclusive, multi-format public consultation | External |
| **Corporate Plan 2023–2024 (MDBA)** | Contextualised project within MDBA's strategic direction and public value objectives | MDBA Corporate Affairs |

**Appendix M**  
Interviews Conducted

1. **Interviews were conducted with the following key stakeholders and users**

**Note:** External stakeholders (e.g. Basin States, First Nations representatives, and community members) were not engaged during this phase. MDBA will lead external engagement separately in future stages, consistent with the current project scope.

| Date | Session | Facilitators | Participants | Key Focus Areas |
| :---- | :---- | :---- | :---- | :---- |
| **17 Apr 2025** | ICT Deep Dive | Jackie Luethi, Odun Obiodun, Will Goodwin, Dale Rogers, Keith Dallinger, Joanna Hill | Ben Bradshaw, Chris Jacob, David Stewart-Thomson, Kim Mayne, Lucy Armstrong, Thao Tran | Systems architecture Data handling Analytics Format flexibility Power BI Automation |
| **22 Apr 2025** | CM\&E Deep Dive | Jackie Luethi, Will Goodwin, Dale Rogers, Joanna Hill | Ed O’Daley, Michelle Fitzgerald, Monique White | Engagement strategies System limitations Trust, feedback loops ICIP risks |
| **24 Apr 2025** | Legal Deep Dive | Jackie Luethi, Will Goodwin, Dale Rogers | Catherine Neidhart | Consent ICIP handling FoI Privacy Act compliance Escalation protocols |
| **28 Apr 2025** | Strategy & Integration Deep Dive | Jackie Luethi, Dale Rogers | Krista Clift | Governance Roles Compliance with Section 51 Campaign handling |
| **28 Apr 2025** | Government Relations Deep Dive | Jackie Luethi, Dale Rogers | Kirsten Henderson, Lauren Roberts | BCC SOG processes State submissions Workflow tracking RACI mapping |
| **30 Apr 2025** | ICIP Deep Dive | Jackie Luethi, Will Goodwin, Dale Rogers, Odun Obiodun, Joanna Hill | Gavin Hesse, Janice Goodwins  | Cultural metadata ICIP consent CARE principles PBC inclusion |
| **7 May 2025** | Cross Disciplinary ICIP Deep Dive | Will Goodwin, Dale Rogers | Jackie Luethi, Odun Obudiun, Gavin Hesse, Maria Donohue, Tracey Langford, Matt Miles, Catherine Neidhart, William Lugg | ICIP Protocols and FPIC Records & Information Management Privacy and FOI Research Governance & Ethics DAMF Integration Redaction & Publication Ethics Metadata & MDBOK enrichment Provenance tracking (as stretch goal) |
| **15 May 2025** | DAMF Map Presentations | Dale Rogers | Jackie Luethi, Odun Obudiun, Matt Miles, Nathan Naicker. | DAMF mapping example presentation Discussion of DAMF map and DAMF catalogue |

**Appendix N**  
Submission Process \+ DAMF Alignment Swimlane

## **Purpose**

This appendix presents the integrated **Service \+ DAMF Process Swimlane** for the Basin Plan Review Submissions Process. It visually maps the complete end-to-end operational workflow across key actors, technology systems, decision points, and data governance responsibilities, while explicitly identifying the alignment with MDBA’s **Data and Analytics Management Framework (DAMF)**.

The diagram serves as both:

* a **service design artefact** (to define the intended end-to-end user and staff experience);

* a **data governance artefact** (to ensure traceability of data as it moves through DAMF stages and is subject to statutory obligations).

## **Context**

The Service Concept (Section 3\) outlines five core journeys:

* Engaged Contribution

* Process Coordination

* Platform Oversight

* Compliance Assurance

* Insight Generation

This swimlane supplements those journeys by:

* adding the explicit DAMF data lifecycle steps of **Plan, Collect, Collate, Process, Analyse, Publish, Preserve, Describe** as defined in the DAMF Guidelines;

* defining how each process phase interacts with data lineage, consent capture, ICIP labelling, redaction, triage, routing, analysis, publication, and archival governance;

* clarifying the integration points between human workflows and MDBA data governance expectations and tools (e.g. DAMF Maps, DAMF Catalogue, MDIP integration).

## **Key Features of the Swimlane**

The following enhancements have been added to reflect 2025 design thinking:

* Addition of the **Consideration Workflow** as a formal decision point to ensure MDBA can demonstrate compliance with the legislative obligation to consider all submissions under Section 51 of the Water Act 2007MDBA\_BPR Process Design…MDBA\_BPR2026\_S\&I\_Deep\_D…MDBA\_BPR2026\_Legal-Deep….

* Introduction of the **Quotation Engine** to enable traceable thematic referencing of submission content into reporting products, such as the What We’ve Heard Report.

* Accommodation of semi-automated and human-in-the-loop **LLM \+ AI-powered data synthesis tools** to assist with bulk campaign handling and thematic analysis;

* Clear process states aligned to DAMF status tracking:

* **Draft (Blue)** – working and incomplete records

* **QA Evaluation (Red)** – reviewed and evaluated data

* **Authorised Product (Gold)** – final records approved for publication and reporting

## **Alignment to MDBA Frameworks**

This artefact ensures direct traceability to the following MDBA design and governance artefacts:

* **MDBA Enterprise Architecture Framework** (principles of Configure-before-Code; Reuse-before-Build; Microsoft stack preference; traceability of data objects)

* **MDBA Data Integration Platform Reference Architecture** (MDIP) (automated pipelines, quality controls, metadata enrichment, records lineage)

* **MDBA DAMF Guide and Mapping Templates** (data lifecycle governance, DAMF Maps and Catalogue)

* **MDBA Digital Strategy 2023–2025** (alignment to digital workplace, platform governance, data stewardship, and operating model objectives)

| Actor / Role | System / Tool | Process Step | Decision Logic / Business Rules | DAMF Status / Notes |
| :---- | :---- | :---- | :---- | :---- |
| **Submitter** | BPR Portal | Submit content, attachments, ICIP declaration | ICIP flag \= True if declared | Create DAMF record; Status \= Draft (Blue); ICIP \= True if flagged |
| **BPR System** | Ingestion Engine \+ AI Pre-screen | Auto-tag metadata, suggest campaign grouping | If similarity \> threshold then assign Campaign Batch ID | Update DAMF metadata; Batch ID assigned |
| **BPR Officer** | Consideration Workflow Engine | Create formal Consideration Record | Must manually acknowledge OR assign to campaign batch | Create DAMF Consideration Record; Considered \= True |
| **BPR Officer** | Redaction Tool (Convalens) | Redact sensitive/PII/ICIP data | Redact if flagged by rules or human judgement | Change DAMF Status → Evaluation (Red) |
| **Privacy / Legal** | Dynamics \+ DAMF | Conduct legal & privacy review | Apply Legal Hold if risk identified | DAMF Legal Hold \= True |
| **Data Analyst** | Power BI \+ SPSS \+ Excel | Perform quantitative analysis | N/A | Link DAMF record to statistical dataset |
| **Data Analyst** | LLM \+ Nvivo \+ AI tools | Conduct qualitative thematic synthesis | If AI confidence \< threshold then escalate to human review | Link DAMF record to synthesis dataset |
| **Policy Officer** | Collaboration Platform | Review data \+ iterate reports | Request further analysis if needed | Update DAMF internal report reference |
| **WWHR Author** | Quotation Engine \+ Authoring Tool | Extract quotes for WWHR \+ link to submission record | N/A | Create DAMF link from WWHR draft to source record |
| **BPR Director** | DAMF Catalogue \+ Dynamics | Approve final WWHR draft | If approved, move to Evaluation Complete | DAMF Status remains Red |
| **Comms Officer** | Publishing System \+ DAMF | Approve \+ release final report | If approved, finalise for public release | DAMF Status \= Authorised Product (Gold); Public URL recorded |
| **Data Steward** | DAMF Catalogue | Archive all datasets \+ reports | N/A | Close DAMF record; Preserve for long-term retention |

## **Usage Note**

This process swimlane is intended to be a living design artefact. It should be updated as the BPR Submissions Process progresses through design, build, and operational delivery phases. The diagram provides a single source of truth for process validation, technical vendor alignment, and internal governance decision points.

All future design decisions for the BPR Submissions System should reference this swimlane to:

* validate DAMF compliance;

* identify service blueprint gaps;

* maintain traceable lineage of any system and process changes that could impact data governance obligations.

**Appendix O**  
Glossary

| Term / Acronym | Definition |
| :---- | :---- |
| **Accessibility** | The design of digital and physical systems so they can be used by people with disabilities, guided by WCAG standards. |
| **Anonymity Preservation** | Measures to ensure submitters who request anonymity are not identifiable in public-facing documents or metadata. |
| **Archetype** | A generalised user type representing shared needs and goals across multiple personas; used to simplify service design. |
| **Audit Trail** | A tamper-proof, timestamped log of all actions taken on a submission; used for defensibility, FOI, and compliance. |
| **Azure AD (Active Directory)** | Microsoft identity management system used for Single Sign-On (SSO) and Multi-Factor Authentication (MFA). |
| **BPR (Basin Plan Review)** | The formal statutory review of the Basin Plan under the \*Water Act 2007\*. |
| **Campaign Submission** | A coordinated, often templated, submission sent by multiple individuals as part of an organised advocacy effort. |
| **CARE Principles** | Governance framework for Indigenous data: Collective Benefit, Authority to Control, Responsibility, and Ethics. |
| **Channel** | The method by which a submission is received (e.g. portal, email, mail, kiosk, phone). |
| **CM\&E** | Communications, Media and Engagement – team responsible for outreach, education, and stakeholder liaison. |
| **Compliance Custodian** | Archetype responsible for ensuring that submissions are handled in line with legal, privacy, and cultural governance obligations. |
| **Consent to Identification** | A submitter’s explicit agreement to have their name published alongside their submission or in reporting materials. |
| **Data Stewardship** | The active management of data to ensure quality, ethical use, sovereignty, and compliance with governance frameworks. |
| **DAMF** | Data and Metadata Framework – MDBA’s internal framework for classification, retention, and archival of data and information assets. |
| **Defamation Risk** | Legal risk associated with publishing harmful or untrue statements in public-facing materials; requires legal review. |
| **Disaster Recovery** | The capability to restore system services and data in the event of failure, breach, or outage. |
| **Engaged Contributor** | Archetype representing community members, stakeholders, and organisations making submissions to the BPR. |
| **Export Manifest** | A structured record of all files and metadata included in a data export, used for audit, FOI, or archival purposes. |
| **FAIR Principle** | A framework for making data Findable, Accessible, Interoperable, and Reusable — commonly used in research to support responsible data sharing and reuse. |
| **FOI (Freedom of Information)** | The *Freedom of Information Act 1982* allows public access to government documents; redacted submissions must be FOI-compliant. |
| **FPIC** | Free, Prior and Informed Consent – a principle requiring clear, informed agreement from First Nations contributors before use of ICIP. |
| **Functional Requirement (FR)** | A system behaviour or function that the service must provide (e.g. file upload, tagging, consent collection). |
| **Guided Kiosk Submission** | Staff-assisted submission entry at outreach events using tablets (e.g. at Riverside Chats). |
| **ICIP** | Indigenous Cultural and Intellectual Property – Indigenous knowledge, stories, practices, and cultural expressions requiring special handling. |
| **ICIP Flag** | A metadata indicator that a submission may contain ICIP content; triggers review workflows and cultural governance controls. |
| **ICT** | Information and Communications Technology – includes system infrastructure, software, and operations. |
| **Insight Curation** | The process of selecting, tagging, and preparing quotes, themes, or evidence from submissions for inclusion in reporting. |
| **Legal Hold** | A directive to preserve specific records or data in anticipation of legal proceedings, FOI, or complaints. |
| **Metadata** | Structured descriptive data attached to a submission (e.g. theme, ICIP status, format, source channel, timestamp). |
| **MFA (Multi-Factor Authentication)** | A security protocol requiring more than one form of authentication before granting access to a system. |
| **NFR (Non-Functional Requirement)** | System qualities that define performance, security, compliance, and maintainability rather than behaviour (e.g. uptime, auditability). |
| **Personas** | Specific, research-based profiles of users representing behaviours, goals, and needs; often inform archetype creation. |
| **PII (Personally Identifiable Information)** | Any data that could identify an individual (e.g. name, email, address); subject to Privacy Act protections. |
| **Platform Guardian** | Archetype responsible for maintaining system availability, monitoring, security, and data handling integrity. |
| **Privacy Act 1988** | Legislation governing how personal information is collected, used, stored, and disclosed by Commonwealth agencies. |
| **Process Steward** | Archetype representing internal teams responsible for managing submission intake, triage, routing, and process compliance. |
| **Publication Consent** | A submitter’s explicit decision to allow their name to be published in outputs such as the *"What We’ve Heard"* report. |
| **RACI Matrix** | A project tool showing who is Responsible, Accountable, Consulted, and Informed for each task or decision. |
| **Redaction** | The removal or obfuscation of sensitive or legally restricted content prior to publication. |
| **Records Officer** | Staff responsible for ensuring submissions are tagged, classified, and archived in line with records and retention requirements. |
| **Retention Tag** | Metadata indicating how long a submission should be retained before it can be disposed of or archived. |
| **Role-Based Access Control (RBAC)** | A security model restricting access to resources based on a user’s role within the organisation. |
| **Service Blueprint** | A diagram showing interactions between users, staff, systems, and processes at each phase of the service. |
| **Service Catalogue** | A register of services delivered by MDBA, including ownership, support levels, and operational responsibilities. |
| **SME (Subject Matter Expert)** | Internal staff with specific technical, legal, cultural, or policy knowledge assigned to review or assess submissions. |
| **Stakeholder Engagement** | The proactive involvement of individuals, communities, and organisations in policy, service design, and decision-making. |
| **Strategic Synthesiser** | Archetype representing users who interpret submission content and generate insights for public and executive reporting. |
| **Submission** | Any written, verbal, or multimedia contribution made by a stakeholder as part of the Basin Plan Review consultation. |
| **Triage** | The process of categorising, tagging, and assigning submissions for processing or escalation based on content or flags. |
| **WWHR (What We’ve Heard Report)** | Public-facing output summarising the major themes and inputs received during the submissions process. |
| **WCAG 2.1 AA** | Accessibility standard ensuring that digital content is usable by people with a wide range of disabilities. |

**Appendix X:**  
Technology Comparison

## **Purpose**

This appendix provides an independent comparison of technology platforms capable of delivering the MDBA Basin Plan Review (BPR) Submissions Management System. It outlines relative strengths, risks, and alignment to MDBA’s Enterprise Architecture principles.

Atturra Advisory provides this advice in an independent advisory capacity. While Atturra’s CBS practice delivers D365 solutions, this analysis is provided free of commercial bias and focused on the client’s stated requirements, operating constraints, and technology landscape preferences.

## **Technology Options Considered**

| Option | Description |
| :---- | :---- |
| **Option 1** | Microsoft D365 \+ Power Apps \+ Power Platform (high alignment to current MDBA stack) |
| **Option 2** | .NET Core \+ React Front-End (high control, high customisation) |
| **Option 3** | Salesforce \+ Lightning Platform (strong case management capabilities) |
| **Option 4** | External COTS Platforms (e.g. Objective, Jadu, Granicus) |
| **Option 5** | Low-Code Bespoke Platforms (e.g. OutSystems, Mendix) |

## 

## **Comparative Analysis**

| Criteria | Option 1:D365 \+ Power Apps | Option 2:.NET \+ React | Option 3:Salesforce | Option 4:COTS Vendor | Option 5:Low-Code |
| :---- | :---- | :---- | :---- | :---- | :---- |
| **MDBA EA Alignment** | Very high | High | Medium | Low to Medium | Low |
| **Security & Compliance** | Excellent (SSO, MFA, RBAC) | Excellent (custom) | Excellent | Variable | Variable |
| **ICIP & Consent Tagging** | Strong (low code customisation) | Custom build required | Custom object modelling | Requires heavy vendor configuration | Limited |
| **Automation / Workflow** | Power Automate native | Azure Logic Apps / Functions | Salesforce Flow / Apex | Varies | Varies |
| **Data Sovereignty** | Azure Australia | Azure Australia | Salesforce Data Centres | Varies | Varies |
| **Front-End User Experience** | Power Apps Portal (plus optional React components) | Fully custom React UI | Lightning Web Components | Vendor-supplied templates | Proprietary |
| **Reporting & Analytics** | Power BI enterprise templates | Power BI via data pipelines | Tableau | Varies | Varies |
| **Data Integration** | Azure Data Lake native | Azure Data Lake native | Requires APIs | Requires APIs | Requires APIs |
| **Implementation Risk** | Low to Medium | High | Medium | Medium | Medium |
| **Cost to Build** | Medium | High | High | Medium | Medium |
| **Cost to Maintain** | Low | High | Medium | Medium | High |
| **Scalability** | Proven at MDBA scale | Proven at MDBA scale | Proven | Varies | Unproven at MDBA scale |
| **Time to Value** | Fast | Slow | Moderate | Fast | Fast |

## **Summary Recommendations**

### **Option 1: D365 \+ Power Apps**

* Most closely aligned to MDBA Digital Strategy and Enterprise Architecture Framework.

* Re-uses existing investment in Microsoft stack (Azure, Power BI, D365).

* Simplifies governance, consent, ICIP tagging, and automation via low-code configuration.

* Strongly preferred option for lowest implementation risk and long-term supportability.

### **Option 2: .NET \+ React**

* Provides ultimate flexibility and full control over design and user experience.

* Suitable for complex ICIP or consent workflows beyond off-the-shelf capability.

* Highest cost, longest delivery time, and requires long-term resourcing commitment.

* Suitable only if custom or unique requirements cannot be met by Option 1\.

### **Option 3: Salesforce**

* Highly capable of delivering robust case management and triage workflows.

* Misaligned with MDBA’s Microsoft cloud strategy and Azure Data Integration Platform.

* Would require duplication of reporting and data lake integration effort.

### **Option 4: External COTS Vendors**

* May offer fast delivery and packaged portals but are unlikely to meet MDBA privacy and ICIP compliance needs without major configuration effort.

* Typically lack deep Power BI integration or Azure-native data flow.

### **Option 5: Low-Code Platforms**

* Useful for rapid prototyping or departmental apps.

* Not recommended for core business critical workloads at scale.

* Higher long-term licence and maintenance costs; lower public sector footprint in Australia.

## **Conclusion**

Based on MDBA’s defined functional and non-functional requirements, security, privacy, data governance, and enterprise architecture principles, **Option 1 (Microsoft D365 \+ Power Platform)** is the recommended solution.

**Option 2 (.NET \+ React)** remains a viable fallback should highly unique requirements emerge during detailed design phases that cannot be met by Power Platform capabilities.

**Disclaimer**

This technology comparison has been prepared by Atturra Advisory for the sole purpose of providing independent advice to MDBA on suitable technology options for the Basin Plan Review Submissions Process. While Atturra Advisory is part of a wider organisation that also delivers Microsoft Dynamics 365 solutions, all care has been taken to ensure an objective, evidence-based analysis aligned to MDBA’s stated requirements and Enterprise Architecture principles. Recommendations are provided without warranty and MDBA must undertake its own detailed procurement and solution selection processes prior to implementation.

Atturra is an Australia-owned, ASX-listed technology   
company providing a range of advisory, consulting,   
IT services and solutions, with a focus on government,   
utilities, higher education, defence, financial services and manufacturing industries. Atturra has partnerships with leading global technology providers and its clients are some of the largest public and private-sector organisations in Australia.

atturra.com  
info@atturra.com